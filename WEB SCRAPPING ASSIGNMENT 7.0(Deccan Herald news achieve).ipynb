{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9230a230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\programdata\\anaconda2\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\programdata\\anaconda2\\lib\\site-packages (from selenium) (1.26.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac60730",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a52eef94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c77c1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f854c290",
   "metadata": {},
   "outputs": [],
   "source": [
    "date1=[]\n",
    "author1=[]\n",
    "vertical1=[]\n",
    "headline1=[]\n",
    "description1=[]\n",
    "\n",
    "# scrapping details 1 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date1.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date1.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author1.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author1.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//li[@class='last']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical1.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical1.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline1.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline1.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-item even']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description1.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description1.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72c30d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame({})\n",
    "df1['Date']=date1[:1]\n",
    "df1['Author']=author1[:1]\n",
    "df1['Vertical']=vertical1[:1]\n",
    "df1['Healines']=headline1[:1]\n",
    "df1['Description']=description1[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a277197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "20acec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date1a=[]\n",
    "author1a=[]\n",
    "vertical1a=[]\n",
    "headline1a=[]\n",
    "description1a=[]\n",
    "\n",
    "# scrapping details 1 may  2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date1a.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date1a.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author1a.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author1a.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='section-container']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical1a.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical1a.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline1a.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline1a.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-item even']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description1a.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description1a.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8852a89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1a=pd.DataFrame({})\n",
    "df1a['Date']=date1a[:1]\n",
    "df1a['Author']=author1a[:1]\n",
    "df1a['Vertical']=vertical1a[:1]\n",
    "df1a['Healines']=headline1a[:1]\n",
    "df1a['Description']=description1a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eef1a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f0d369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b84cb885",
   "metadata": {},
   "outputs": [],
   "source": [
    "date1b=[]\n",
    "author1b=[]\n",
    "vertical1b=[]\n",
    "headline1b=[]\n",
    "description1b=[]\n",
    "\n",
    "# scrapping details 1 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date1b.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date1b.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author1b.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author1b.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='section-container']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical1b.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical1b.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline1b.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline1b.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description1b.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description1b.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c03a597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1b=pd.DataFrame({})\n",
    "df1b['Date']=date1b[:1]\n",
    "df1b['Author']=author1b[:1]\n",
    "df1b['Vertical']=vertical1b[:1]\n",
    "df1b['Healines']=headline1b[:1]\n",
    "df1b['Description']=description1b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9affe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9d02d384",
   "metadata": {},
   "outputs": [],
   "source": [
    "date1c=[]\n",
    "author1c=[]\n",
    "vertical1c=[]\n",
    "headline1c=[]\n",
    "description1c=[]\n",
    "\n",
    "# scrapping details 4 may 2021k\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date1c.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date1c.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author1c.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author1c.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='section-container']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical1c.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical1c.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline1c.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline1c.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description1c.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description1c.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "654d965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1c=pd.DataFrame({})\n",
    "df1c['Date']=date1c[:1]\n",
    "df1c['Author']=author1c[:1]\n",
    "df1c['Vertical']=vertical1c[:1]\n",
    "df1c['Healines']=headline1c[:1]\n",
    "df1c['Description']=description1c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f28062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a850ae28",
   "metadata": {},
   "outputs": [],
   "source": [
    "date1d=[]\n",
    "author1d=[]\n",
    "vertical1d=[]\n",
    "headline1d=[]\n",
    "description1d=[]\n",
    "\n",
    "# scrapping details 1 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date1d.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date1d.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author1d.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author1d.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical1d.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical1d.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline1d.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline1d.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description1d.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description1d.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f0518e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1d=pd.DataFrame({})\n",
    "df1d['Date']=date1d[:1]\n",
    "df1d['Author']=author1d[:1]\n",
    "df1d['Vertical']=vertical1d[:1]\n",
    "df1d['Healines']=headline1d[:1]\n",
    "df1d['Description']=description1d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ba3112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e91f4fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "date1e=[]\n",
    "author1e=[]\n",
    "vertical1e=[]\n",
    "headline1e=[]\n",
    "description1e=[]\n",
    "\n",
    "# scrapping details 1 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date1e.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date1e.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author1e.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author1e.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical1e.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical1e.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline1e.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline1e.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description1e.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description1e.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a6e53bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1e=pd.DataFrame({})\n",
    "df1e['Date']=date1e[:1]\n",
    "df1e['Author']=author1e[:1]\n",
    "df1e['Vertical']=vertical1e[:1]\n",
    "df1e['Healines']=headline1e[:1]\n",
    "df1e['Description']=description1e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dec04f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "08a9b952",
   "metadata": {},
   "outputs": [],
   "source": [
    "date1f=[]\n",
    "author1f=[]\n",
    "vertical1f=[]\n",
    "headline1f=[]\n",
    "description1f=[]\n",
    "\n",
    "# scrapping details 1 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date1f.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date1f.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author1f.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author1f.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical1f.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical1f.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline1f.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline1f.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description1f.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description1f.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8f372797",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1f=pd.DataFrame({})\n",
    "df1f['Date']=date1f[:1]\n",
    "df1f['Author']=author1f[:1]\n",
    "df1f['Vertical']=vertical1f[:1]\n",
    "df1f['Healines']=headline1f[:1]\n",
    "df1f['Description']=description1f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de6388d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "28743e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "date1g=[]\n",
    "author1g=[]\n",
    "vertical1g=[]\n",
    "headline1g=[]\n",
    "description1g=[]\n",
    "\n",
    "# scrapping details 1 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date1g.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date1g.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author1g.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author1g.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical1g.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical1g.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline1g.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline1g.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description1g.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description1g.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ff88895d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1g=pd.DataFrame({})\n",
    "df1g['Date']=date1g[:1]\n",
    "df1g['Author']=author1g[:1]\n",
    "df1g['Vertical']=vertical1g[:1]\n",
    "df1g['Healines']=headline1g[:1]\n",
    "df1g['Description']=description1g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b362e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c7e7b4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "date1h=[]\n",
    "author1h=[]\n",
    "vertical1h=[]\n",
    "headline1h=[]\n",
    "description1h=[]\n",
    "\n",
    "# scrapping details 1 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date1h.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date1h.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author1h.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author1h.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical1h.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical1h.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline1h.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline1h.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description1h.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description1h.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "51334388",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1h=pd.DataFrame({})\n",
    "df1h['Date']=date1h[:1]\n",
    "df1h['Author']=author1h[:1]\n",
    "df1h['Vertical']=vertical1h[:1]\n",
    "df1h['Healines']=headline1h[:1]\n",
    "df1h['Description']=description1h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801b2946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a02d0c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "date1i=[]\n",
    "author1i=[]\n",
    "vertical1i=[]\n",
    "headline1i=[]\n",
    "description1i=[]\n",
    "\n",
    "# scrapping details 1 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date1i.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date1i.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author1i.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author1i.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical1i.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical1i.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline1i.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline1i.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description1i.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description1i.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d483bcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1i=pd.DataFrame({})\n",
    "df1i['Date']=date1i[:1]\n",
    "df1i['Author']=author1i[:1]\n",
    "df1i['Vertical']=vertical1i[:1]\n",
    "df1i['Healines']=headline1i[:1]\n",
    "df1i['Description']=description1i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71295893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3072f44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "45a79f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "date2=[]\n",
    "author2=[]\n",
    "vertical2=[]\n",
    "headline2=[]\n",
    "description2=[]\n",
    "\n",
    "# scrapping details 2 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date2.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date2.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author2.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author2.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical2.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical2.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline2.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline2.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description2.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description2.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b7663809",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame({})\n",
    "df2['Date']=date2[:1]\n",
    "df2['Author']=author2[:1]\n",
    "df2['Vertical']=vertical2[:1]\n",
    "df2['Healines']=headline2[:1]\n",
    "df2['Description']=description2[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb916ade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "37b89e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "date2a=[]\n",
    "author2a=[]\n",
    "vertical2a=[]\n",
    "headline2a=[]\n",
    "description2a=[]\n",
    "\n",
    "# scrapping details 2 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date2a.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date2a.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author2a.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author2a.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical2a.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical2a.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline2a.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline2a.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description2a.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description2a.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c7ead4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2a=pd.DataFrame({})\n",
    "df2a['Date']=date2a[:1]\n",
    "df2a['Author']=author2a[:1]\n",
    "df2a['Vertical']=vertical2a[:1]\n",
    "df2a['Healines']=headline2a[:1]\n",
    "df2a['Description']=description2a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f545bda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "39bf1c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "date2b=[]\n",
    "author2b=[]\n",
    "vertical2b=[]\n",
    "headline2b=[]\n",
    "description2b=[]\n",
    "\n",
    "# scrapping details 2 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date2b.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date2b.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author2b.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author2b.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical2b.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical2b.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline2b.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline2b.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description2b.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description2b.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4c4735e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2b=pd.DataFrame({})\n",
    "df2b['Date']=date2b[:1]\n",
    "df2b['Author']=author2b[:1]\n",
    "df2b['Vertical']=vertical2b[:1]\n",
    "df2b['Healines']=headline2b[:1]\n",
    "df2b['Description']=description2b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2666ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e8bb62be",
   "metadata": {},
   "outputs": [],
   "source": [
    "date2c=[]\n",
    "author2c=[]\n",
    "vertical2c=[]\n",
    "headline2c=[]\n",
    "description2c=[]\n",
    "\n",
    "# scrapping details 2 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date2c.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date2c.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author2c.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author2c.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical2c.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical2c.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline2c.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline2c.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description2c.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description2c.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ee8c6d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2c=pd.DataFrame({})\n",
    "df2c['Date']=date2c[:1]\n",
    "df2c['Author']=author2c[:1]\n",
    "df2c['Vertical']=vertical2c[:1]\n",
    "df2c['Healines']=headline2c[:1]\n",
    "df2c['Description']=description2c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a228053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e9f18b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date2d=[]\n",
    "author2d=[]\n",
    "vertical2d=[]\n",
    "headline2d=[]\n",
    "description2d=[]\n",
    "\n",
    "# scrapping details 2 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date2d.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date2d.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author2d.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author2d.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical2d.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical2d.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline2d.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline2d.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description2d.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description2d.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "121f9f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2d=pd.DataFrame({})\n",
    "df2d['Date']=date2d[:1]\n",
    "df2d['Author']=author2d[:1]\n",
    "df2d['Vertical']=vertical2d[:1]\n",
    "df2d['Healines']=headline2d[:1]\n",
    "df2d['Description']=description2d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc837ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a6410fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "date2e=[]\n",
    "author2e=[]\n",
    "vertical2e=[]\n",
    "headline2e=[]\n",
    "description2e=[]\n",
    "\n",
    "# scrapping details 2 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date2e.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date2e.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author2e.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author2e.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical2e.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical2e.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline2e.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline2e.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description2e.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description2e.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d67c8683",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2e=pd.DataFrame({})\n",
    "df2e['Date']=date2e[:1]\n",
    "df2e['Author']=author2e[:1]\n",
    "df2e['Vertical']=vertical2e[:1]\n",
    "df2e['Healines']=headline2e[:1]\n",
    "df2e['Description']=description2e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d651440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cee4fa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "date2f=[]\n",
    "author2f=[]\n",
    "vertical2f=[]\n",
    "headline2f=[]\n",
    "description2f=[]\n",
    "\n",
    "# scrapping details 2 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date2f.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date2f.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author2f.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author2f.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical2f.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical2f.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline2f.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline2f.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description2f.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description2f.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "70c58916",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2f=pd.DataFrame({})\n",
    "df2f['Date']=date2f[:1]\n",
    "df2f['Author']=author2f[:1]\n",
    "df2f['Vertical']=vertical2f[:1]\n",
    "df2f['Healines']=headline2f[:1]\n",
    "df2f['Description']=description2f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168b921e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e5206c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date2g=[]\n",
    "author2g=[]\n",
    "vertical2g=[]\n",
    "headline2g=[]\n",
    "description2g=[]\n",
    "\n",
    "# scrapping details 2 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date2g.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date2g.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author2g.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author2g.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical2g.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical2g.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline2g.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline2g.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description2g.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description2g.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9fda0d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2g=pd.DataFrame({})\n",
    "df2g['Date']=date2g[:1]\n",
    "df2g['Author']=author2g[:1]\n",
    "df2g['Vertical']=vertical2g[:1]\n",
    "df2g['Healines']=headline2g[:1]\n",
    "df2g['Description']=description2g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35845698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b73e15fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "date2h=[]\n",
    "author2h=[]\n",
    "vertical2h=[]\n",
    "headline2h=[]\n",
    "description2h=[]\n",
    "\n",
    "# scrapping details 2 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date2h.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date2h.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author2h.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author2h.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical2h.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical2h.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline2h.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline2h.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description2h.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description2h.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "736902b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2h=pd.DataFrame({})\n",
    "df2h['Date']=date2h[:1]\n",
    "df2h['Author']=author2h[:1]\n",
    "df2h['Vertical']=vertical2h[:1]\n",
    "df2h['Healines']=headline2h[:1]\n",
    "df2h['Description']=description2h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3516c48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a7a911af",
   "metadata": {},
   "outputs": [],
   "source": [
    "date2i=[]\n",
    "author2i=[]\n",
    "vertical2i=[]\n",
    "headline2i=[]\n",
    "description2i=[]\n",
    "\n",
    "# scrapping details 2 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date2i.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date2i.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author2i.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author2i.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical2i.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical2i.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline2i.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline2i.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description2i.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description2i.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "57cb038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2i=pd.DataFrame({})\n",
    "df2i['Date']=date2i[:1]\n",
    "df2i['Author']=author2i[:1]\n",
    "df2i['Vertical']=vertical2i[:1]\n",
    "df2i['Healines']=headline2i[:1]\n",
    "df2i['Description']=description2i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f23a339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0006440b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "58216804",
   "metadata": {},
   "outputs": [],
   "source": [
    "date3=[]\n",
    "author3=[]\n",
    "vertical3=[]\n",
    "headline3=[]\n",
    "description3=[]\n",
    "\n",
    "# scrapping details 3 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date3.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date3.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author3.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author3.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical3.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical3.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline3.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline3.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description3.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description3.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6fec5d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=pd.DataFrame({})\n",
    "df3['Date']=date3[:1]\n",
    "df3['Author']=author3[:1]\n",
    "df3['Vertical']=vertical3[:1]\n",
    "df3['Healines']=headline3[:1]\n",
    "df3['Description']=description3[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337342d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "94930832",
   "metadata": {},
   "outputs": [],
   "source": [
    "date3a=[]\n",
    "author3a=[]\n",
    "vertical3a=[]\n",
    "headline3a=[]\n",
    "description3a=[]\n",
    "\n",
    "# scrapping details 3 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date3a.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date3a.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author3a.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author3a.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical3a.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical3a.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline3a.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline3a.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description3a.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description3a.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c742a37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3a=pd.DataFrame({})\n",
    "df3a['Date']=date3a[:1]\n",
    "df3a['Author']=author3a[:1]\n",
    "df3a['Vertical']=vertical3a[:1]\n",
    "df3a['Healines']=headline3a[:1]\n",
    "df3a['Description']=description3a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cad501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5025853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date3b=[]\n",
    "author3b=[]\n",
    "vertical3b=[]\n",
    "headline3b=[]\n",
    "description3b=[]\n",
    "\n",
    "# scrapping details 3 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date3b.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date3b.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author3b.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author3b.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical3b.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical3b.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline3b.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline3b.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description3b.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description3b.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ed855909",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3b=pd.DataFrame({})\n",
    "df3b['Date']=date3b[:1]\n",
    "df3b['Author']=author3b[:1]\n",
    "df3b['Vertical']=vertical3b[:1]\n",
    "df3b['Healines']=headline3b[:1]\n",
    "df3b['Description']=description3b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193caf91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "707882e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "date3c=[]\n",
    "author3c=[]\n",
    "vertical3c=[]\n",
    "headline3c=[]\n",
    "description3c=[]\n",
    "\n",
    "# scrapping details 3 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date3c.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date3c.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author3c.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author3c.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical3c.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical3c.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline3c.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline3c.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description3c.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description3c.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f261c4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3c=pd.DataFrame({})\n",
    "df3c['Date']=date3c[:1]\n",
    "df3c['Author']=author3c[:1]\n",
    "df3c['Vertical']=vertical3c[:1]\n",
    "df3c['Healines']=headline3c[:1]\n",
    "df3c['Description']=description3c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5358e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e5c7c6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "date3d=[]\n",
    "author3d=[]\n",
    "vertical3d=[]\n",
    "headline3d=[]\n",
    "description3d=[]\n",
    "\n",
    "# scrapping details 3 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date3d.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date3d.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author3d.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author3d.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical3d.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical3d.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline3d.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline3d.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description3d.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description3d.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5bb4aa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3d=pd.DataFrame({})\n",
    "df3d['Date']=date3d[:1]\n",
    "df3d['Author']=author3d[:1]\n",
    "df3d['Vertical']=vertical3d[:1]\n",
    "df3d['Healines']=headline3d[:1]\n",
    "df3d['Description']=description3d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91919826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ad80886f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date3e=[]\n",
    "author3e=[]\n",
    "vertical3e=[]\n",
    "headline3e=[]\n",
    "description3e=[]\n",
    "\n",
    "# scrapping details 3 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date3e.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date3e.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author3e.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author3e.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical3e.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical3e.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline3e.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline3e.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description3e.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description3e.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "28e3e443",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3e=pd.DataFrame({})\n",
    "df3e['Date']=date3e[:1]\n",
    "df3e['Author']=author3e[:1]\n",
    "df3e['Vertical']=vertical3e[:1]\n",
    "df3e['Healines']=headline3e[:1]\n",
    "df3e['Description']=description3e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0603b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7af33fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "date3f=[]\n",
    "author3f=[]\n",
    "vertical3f=[]\n",
    "headline3f=[]\n",
    "description3f=[]\n",
    "\n",
    "# scrapping details 3 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date3f.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date3f.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author3f.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author3f.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical3f.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical3f.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline3f.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline3f.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description3f.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description3f.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "20352de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3f=pd.DataFrame({})\n",
    "df3f['Date']=date3f[:1]\n",
    "df3f['Author']=author3f[:1]\n",
    "df3f['Vertical']=vertical3f[:1]\n",
    "df3f['Healines']=headline3f[:1]\n",
    "df3f['Description']=description3f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dac626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e51f32e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "date3g=[]\n",
    "author3g=[]\n",
    "vertical3g=[]\n",
    "headline3g=[]\n",
    "description3g=[]\n",
    "\n",
    "# scrapping details 3 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date3g.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date3g.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author3g.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author3g.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical3g.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical3g.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline3g.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline3g.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description3g.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description3g.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cef1503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3g=pd.DataFrame({})\n",
    "df3g['Date']=date3g[:1]\n",
    "df3g['Author']=author3g[:1]\n",
    "df3g['Vertical']=vertical3g[:1]\n",
    "df3g['Healines']=headline3g[:1]\n",
    "df3g['Description']=description3g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58c6352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6e85afba",
   "metadata": {},
   "outputs": [],
   "source": [
    "date3h=[]\n",
    "author3h=[]\n",
    "vertical3h=[]\n",
    "headline3h=[]\n",
    "description3h=[]\n",
    "\n",
    "# scrapping details 3 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date3h.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date3h.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author3h.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author3h.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical3h.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical3h.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline3h.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline3h.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description3h.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description3h.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3e907ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3h=pd.DataFrame({})\n",
    "df3h['Date']=date3h[:1]\n",
    "df3h['Author']=author3h[:1]\n",
    "df3h['Vertical']=vertical3h[:1]\n",
    "df3h['Healines']=headline3h[:1]\n",
    "df3h['Description']=description3h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d06409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "46d46003",
   "metadata": {},
   "outputs": [],
   "source": [
    "date3i=[]\n",
    "author3i=[]\n",
    "vertical3i=[]\n",
    "headline3i=[]\n",
    "description3i=[]\n",
    "\n",
    "# scrapping details 3 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date3i.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date3i.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author3i.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author3i.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical3i.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical3i.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline3i.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline3i.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description3i.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description3i.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "598ea319",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3i=pd.DataFrame({})\n",
    "df3i['Date']=date3i[:1]\n",
    "df3i['Author']=author3i[:1]\n",
    "df3i['Vertical']=vertical3i[:1]\n",
    "df3i['Healines']=headline3i[:1]\n",
    "df3i['Description']=description3i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e097c3db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636bd514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "94806053",
   "metadata": {},
   "outputs": [],
   "source": [
    "date4=[]\n",
    "author4=[]\n",
    "vertical4=[]\n",
    "headline4=[]\n",
    "description4=[]\n",
    "\n",
    "# scrapping details 4 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date4.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author4.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical4.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline4.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description4.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "66a90ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=pd.DataFrame({})\n",
    "df4['Date']=date4[:1]\n",
    "df4['Author']=author4[:1]\n",
    "df4['Vertical']=vertical4[:1]\n",
    "df4['Healines']=headline4[:1]\n",
    "df4['Description']=description4[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9196726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "11dcab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "date4a=[]\n",
    "author4a=[]\n",
    "vertical4a=[]\n",
    "headline4a=[]\n",
    "description4a=[]\n",
    "\n",
    "# scrapping details 4 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date4a.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author4a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical4a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline4a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description4a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e6a48d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4a=pd.DataFrame({})\n",
    "df4a['Date']=date4a[:1]\n",
    "df4a['Author']=author4a[:1]\n",
    "df4a['Vertical']=vertical4a[:1]\n",
    "df4a['Healines']=headline4a[:1]\n",
    "df4a['Description']=description4a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2bb864",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2b7ed7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "date4b=[]\n",
    "author4b=[]\n",
    "vertical4b=[]\n",
    "headline4b=[]\n",
    "description4b=[]\n",
    "\n",
    "# scrapping details 4 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date4b.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author4b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical4b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline4b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description4b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e172c7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4b=pd.DataFrame({})\n",
    "df4b['Date']=date4b[:1]\n",
    "df4b['Author']=author4b[:1]\n",
    "df4b['Vertical']=vertical4b[:1]\n",
    "df4b['Healines']=headline4b[:1]\n",
    "df4b['Description']=description4b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526956aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "26903369",
   "metadata": {},
   "outputs": [],
   "source": [
    "date4c=[]\n",
    "author4c=[]\n",
    "vertical4c=[]\n",
    "headline4c=[]\n",
    "description4c=[]\n",
    "\n",
    "# scrapping details 4 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date4c.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author4c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical4c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline4c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description4c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fe0ce7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4c=pd.DataFrame({})\n",
    "df4c['Date']=date4c[:1]\n",
    "df4c['Author']=author4c[:1]\n",
    "df4c['Vertical']=vertical4c[:1]\n",
    "df4c['Healines']=headline4c[:1]\n",
    "df4c['Description']=description4c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d750455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "37b6018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date4d=[]\n",
    "author4d=[]\n",
    "vertical4d=[]\n",
    "headline4d=[]\n",
    "description4d=[]\n",
    "\n",
    "# scrapping details 4 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date4d.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author4d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical4d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline4d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description4d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4e691c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4d=pd.DataFrame({})\n",
    "df4d['Date']=date4d[:1]\n",
    "df4d['Author']=author4d[:1]\n",
    "df4d['Vertical']=vertical4d[:1]\n",
    "df4d['Healines']=headline4d[:1]\n",
    "df4d['Description']=description4d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4e6301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4db626c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "date4e=[]\n",
    "author4e=[]\n",
    "vertical4e=[]\n",
    "headline4e=[]\n",
    "description4e=[]\n",
    "\n",
    "# scrapping details 4 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date4e.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author4e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical4e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline4e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description4e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "fcd9a7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4e=pd.DataFrame({})\n",
    "df4e['Date']=date4e[:1]\n",
    "df4e['Author']=author4e[:1]\n",
    "df4e['Vertical']=vertical4e[:1]\n",
    "df4e['Healines']=headline4e[:1]\n",
    "df4e['Description']=description4e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a61b42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4258ae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "date4f=[]\n",
    "author4f=[]\n",
    "vertical4f=[]\n",
    "headline4f=[]\n",
    "description4f=[]\n",
    "\n",
    "# scrapping details 4 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date4f.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author4f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical4f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline4f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description4f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b5844def",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4f=pd.DataFrame({})\n",
    "df4f['Date']=date4f[:1]\n",
    "df4f['Author']=author4f[:1]\n",
    "df4f['Vertical']=vertical4f[:1]\n",
    "df4f['Healines']=headline4f[:1]\n",
    "df4f['Description']=description4f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6ff645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f2e11b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "date4g=[]\n",
    "author4g=[]\n",
    "vertical4g=[]\n",
    "headline4g=[]\n",
    "description4g=[]\n",
    "\n",
    "# scrapping details 4 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date4g.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author4g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical4g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline4g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description4g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "eb1efc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4g=pd.DataFrame({})\n",
    "df4g['Date']=date4g[:1]\n",
    "df4g['Author']=author4g[:1]\n",
    "df4g['Vertical']=vertical4g[:1]\n",
    "df4g['Healines']=headline4g[:1]\n",
    "df4g['Description']=description4g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a454e7e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "25624873",
   "metadata": {},
   "outputs": [],
   "source": [
    "date4h=[]\n",
    "author4h=[]\n",
    "vertical4h=[]\n",
    "headline4h=[]\n",
    "description4h=[]\n",
    "\n",
    "# scrapping details 4 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date4h.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author4h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical4h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline4h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description4h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d1a672fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4h=pd.DataFrame({})\n",
    "df4h['Date']=date4h[:1]\n",
    "df4h['Author']=author4h[:1]\n",
    "df4h['Vertical']=vertical4h[:1]\n",
    "df4h['Healines']=headline4h[:1]\n",
    "df4h['Description']=description4h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69ee4f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b3952e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "date4i=[]\n",
    "author4i=[]\n",
    "vertical4i=[]\n",
    "headline4i=[]\n",
    "description4i=[]\n",
    "\n",
    "# scrapping details 4 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date4i.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author4i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical4i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline4i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description4i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bc549bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4i=pd.DataFrame({})\n",
    "df4i['Date']=date4i[:1]\n",
    "df4i['Author']=author4i[:1]\n",
    "df4i['Vertical']=vertical4i[:1]\n",
    "df4i['Healines']=headline4i[:1]\n",
    "df4i['Description']=description4i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7678d303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef01aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "edc73227",
   "metadata": {},
   "outputs": [],
   "source": [
    "date5=[]\n",
    "author5=[]\n",
    "vertical5=[]\n",
    "headline5=[]\n",
    "description5=[]\n",
    "\n",
    "# scrapping details 5 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date5.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author5.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical5.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline5.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description5.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "70b0dafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5=pd.DataFrame({})\n",
    "df5['Date']=date5[:1]\n",
    "df5['Author']=author5[:1]\n",
    "df5['Vertical']=vertical5[:1]\n",
    "df5['Healines']=headline5[:1]\n",
    "df5['Description']=description5[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bd9c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7d88c2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "date5a=[]\n",
    "author5a=[]\n",
    "vertical5a=[]\n",
    "headline5a=[]\n",
    "description5a=[]\n",
    "\n",
    "# scrapping details 5 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date5a.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author5a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical5a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline5a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description5a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "45fc0877",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5a=pd.DataFrame({})\n",
    "df5a['Date']=date5a[:1]\n",
    "df5a['Author']=author5a[:1]\n",
    "df5a['Vertical']=vertical5a[:1]\n",
    "df5a['Healines']=headline5a[:1]\n",
    "df5a['Description']=description5a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1fc0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4623f288",
   "metadata": {},
   "outputs": [],
   "source": [
    "date5b=[]\n",
    "author5b=[]\n",
    "vertical5b=[]\n",
    "headline5b=[]\n",
    "description5b=[]\n",
    "\n",
    "# scrapping details 5 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date5b.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author5b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical5b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline5b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description5b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "fd46bd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5b=pd.DataFrame({})\n",
    "df5b['Date']=date5b[:1]\n",
    "df5b['Author']=author5b[:1]\n",
    "df5b['Vertical']=vertical5b[:1]\n",
    "df5b['Healines']=headline5b[:1]\n",
    "df5b['Description']=description5b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251665e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5d0db1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "date5c=[]\n",
    "author5c=[]\n",
    "vertical5c=[]\n",
    "headline5c=[]\n",
    "description5c=[]\n",
    "\n",
    "# scrapping details 5 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date5c.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author5c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical5c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline5c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description5c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "651579df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5c=pd.DataFrame({})\n",
    "df5c['Date']=date5c[:1]\n",
    "df5c['Author']=author5c[:1]\n",
    "df5c['Vertical']=vertical5c[:1]\n",
    "df5c['Healines']=headline5c[:1]\n",
    "df5c['Description']=description5c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccd4bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d7aa740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date5d=[]\n",
    "author5d=[]\n",
    "vertical5d=[]\n",
    "headline5d=[]\n",
    "description5d=[]\n",
    "\n",
    "# scrapping details 5 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date5d.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author5d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical5d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline5d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description5d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ead789e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5d=pd.DataFrame({})\n",
    "df5d['Date']=date5d[:1]\n",
    "df5d['Author']=author5d[:1]\n",
    "df5d['Vertical']=vertical5d[:1]\n",
    "df5d['Healines']=headline5d[:1]\n",
    "df5d['Description']=description5d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27da1674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8a37650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "date5e=[]\n",
    "author5e=[]\n",
    "vertical5e=[]\n",
    "headline5e=[]\n",
    "description5e=[]\n",
    "\n",
    "# scrapping details 5 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date5e.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author5e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical5e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline5e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description5e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ce7d0b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5e=pd.DataFrame({})\n",
    "df5e['Date']=date5e[:1]\n",
    "df5e['Author']=author5e[:1]\n",
    "df5e['Vertical']=vertical5e[:1]\n",
    "df5e['Healines']=headline5e[:1]\n",
    "df5e['Description']=description5e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6410896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "bff6374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date5f=[]\n",
    "author5f=[]\n",
    "vertical5f=[]\n",
    "headline5f=[]\n",
    "description5f=[]\n",
    "\n",
    "# scrapping details 5 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date5f.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author5f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical5f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline5f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description5f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "eefcd0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5f=pd.DataFrame({})\n",
    "df5f['Date']=date5f[:1]\n",
    "df5f['Author']=author5f[:1]\n",
    "df5f['Vertical']=vertical5f[:1]\n",
    "df5f['Healines']=headline5f[:1]\n",
    "df5f['Description']=description5f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1716ff39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "16b3f144",
   "metadata": {},
   "outputs": [],
   "source": [
    "date5g=[]\n",
    "author5g=[]\n",
    "vertical5g=[]\n",
    "headline5g=[]\n",
    "description5g=[]\n",
    "\n",
    "# scrapping details 5 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date5g.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author5g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical5g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline5g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description5g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e006c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5g=pd.DataFrame({})\n",
    "df5g['Date']=date5g[:1]\n",
    "df5g['Author']=author5g[:1]\n",
    "df5g['Vertical']=vertical5g[:1]\n",
    "df5g['Healines']=headline5g[:1]\n",
    "df5g['Description']=description5g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bf04d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "cdab1c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "date5h=[]\n",
    "author5h=[]\n",
    "vertical5h=[]\n",
    "headline5h=[]\n",
    "description5h=[]\n",
    "\n",
    "# scrapping details 5 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date5h.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author5h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical5h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline5h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description5h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e442dd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5h=pd.DataFrame({})\n",
    "df5h['Date']=date5h[:1]\n",
    "df5h['Author']=author5h[:1]\n",
    "df5h['Vertical']=vertical5h[:1]\n",
    "df5h['Healines']=headline5h[:1]\n",
    "df5h['Description']=description5h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cca0118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "52f3fe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date5i=[]\n",
    "author5i=[]\n",
    "vertical5i=[]\n",
    "headline5i=[]\n",
    "description5i=[]\n",
    "\n",
    "# scrapping details 5 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date5i.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author5i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical5i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline5i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description5i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9593fc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5i=pd.DataFrame({})\n",
    "df5i['Date']=date5i[:1]\n",
    "df5i['Author']=author5i[:1]\n",
    "df5i['Vertical']=vertical5i[:1]\n",
    "df5i['Healines']=headline5i[:1]\n",
    "df5i['Description']=description5i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9510c0e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15c2db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "173a5eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "date6=[]\n",
    "author6=[]\n",
    "vertical6=[]\n",
    "headline6=[]\n",
    "description6=[]\n",
    "\n",
    "# scrapping details 6 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date6.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author6.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical6.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline6.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description6.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "8e815714",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6=pd.DataFrame({})\n",
    "df6['Date']=date6[:1]\n",
    "df6['Author']=author6[:1]\n",
    "df6['Vertical']=vertical6[:1]\n",
    "df6['Healines']=headline6[:1]\n",
    "df6['Description']=description6[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1263c670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "6d1365ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "date6a=[]\n",
    "author6a=[]\n",
    "vertical6a=[]\n",
    "headline6a=[]\n",
    "description6a=[]\n",
    "\n",
    "# scrapping details 6 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date6a.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author6a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical6a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline6a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description6a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7c0d4902",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6a=pd.DataFrame({})\n",
    "df6a['Date']=date6a[:1]\n",
    "df6a['Author']=author6a[:1]\n",
    "df6a['Vertical']=vertical6a[:1]\n",
    "df6a['Healines']=headline6a[:1]\n",
    "df6a['Description']=description6a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1a5166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "39569a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "date6b=[]\n",
    "author6b=[]\n",
    "vertical6b=[]\n",
    "headline6b=[]\n",
    "description6b=[]\n",
    "\n",
    "# scrapping details 6 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date6b.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author6b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical6b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline6b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description6b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "729c88c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6b=pd.DataFrame({})\n",
    "df6b['Date']=date6b[:1]\n",
    "df6b['Author']=author6b[:1]\n",
    "df6b['Vertical']=vertical6b[:1]\n",
    "df6b['Healines']=headline6b[:1]\n",
    "df6b['Description']=description6b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1c6a49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "42040019",
   "metadata": {},
   "outputs": [],
   "source": [
    "date6c=[]\n",
    "author6c=[]\n",
    "vertical6c=[]\n",
    "headline6c=[]\n",
    "description6c=[]\n",
    "\n",
    "# scrapping details 6 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date6c.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author6c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical6c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline6c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description6c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a4e4c939",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6c=pd.DataFrame({})\n",
    "df6c['Date']=date6c[:1]\n",
    "df6c['Author']=author6c[:1]\n",
    "df6c['Vertical']=vertical6c[:1]\n",
    "df6c['Healines']=headline6c[:1]\n",
    "df6c['Description']=description6c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be6e453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "edce83e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "date6d=[]\n",
    "author6d=[]\n",
    "vertical6d=[]\n",
    "headline6d=[]\n",
    "description6d=[]\n",
    "\n",
    "# scrapping details 6 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date6d.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author6d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical6d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline6d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description6d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "aa047d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6d=pd.DataFrame({})\n",
    "df6d['Date']=date6d[:1]\n",
    "df6d['Author']=author6d[:1]\n",
    "df6d['Vertical']=vertical6d[:1]\n",
    "df6d['Healines']=headline6d[:1]\n",
    "df6d['Description']=description6d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4b6f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "3b1e0873",
   "metadata": {},
   "outputs": [],
   "source": [
    "date6e=[]\n",
    "author6e=[]\n",
    "vertical6e=[]\n",
    "headline6e=[]\n",
    "description6e=[]\n",
    "\n",
    "# scrapping details 6 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date6e.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author6e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical6e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline6e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description6e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9f1a0e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6e=pd.DataFrame({})\n",
    "df6e['Date']=date6e[:1]\n",
    "df6e['Author']=author6e[:1]\n",
    "df6e['Vertical']=vertical6e[:1]\n",
    "df6e['Healines']=headline6e[:1]\n",
    "df6e['Description']=description6e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60c8e85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "baf004e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "date6f=[]\n",
    "author6f=[]\n",
    "vertical6f=[]\n",
    "headline6f=[]\n",
    "description6f=[]\n",
    "\n",
    "# scrapping details 6 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date6f.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author6f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical6f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline6f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description6f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e64fa5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6f=pd.DataFrame({})\n",
    "df6f['Date']=date6f[:1]\n",
    "df6f['Author']=author6f[:1]\n",
    "df6f['Vertical']=vertical6f[:1]\n",
    "df6f['Healines']=headline6f[:1]\n",
    "df6f['Description']=description6f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c854abd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "363690a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "date6g=[]\n",
    "author6g=[]\n",
    "vertical6g=[]\n",
    "headline6g=[]\n",
    "description6g=[]\n",
    "\n",
    "# scrapping details 6 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date6g.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author6g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical6g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline6g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description6g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "787afac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6g=pd.DataFrame({})\n",
    "df6g['Date']=date6g[:1]\n",
    "df6g['Author']=author6g[:1]\n",
    "df6g['Vertical']=vertical6g[:1]\n",
    "df6g['Healines']=headline6g[:1]\n",
    "df6g['Description']=description6g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74def62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a486813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date6h=[]\n",
    "author6h=[]\n",
    "vertical6h=[]\n",
    "headline6h=[]\n",
    "description6h=[]\n",
    "\n",
    "# scrapping details 6 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date6h.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author6h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical6h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline6h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description6h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "6b46dc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6h=pd.DataFrame({})\n",
    "df6h['Date']=date6h[:1]\n",
    "df6h['Author']=author6h[:1]\n",
    "df6h['Vertical']=vertical6h[:1]\n",
    "df6h['Healines']=headline6h[:1]\n",
    "df6h['Description']=description6h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32168e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f823811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "date6i=[]\n",
    "author6i=[]\n",
    "vertical6i=[]\n",
    "headline6i=[]\n",
    "description6i=[]\n",
    "\n",
    "# scrapping details 6 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date6i.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author6i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical6i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline6i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description6i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f0bc4480",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6i=pd.DataFrame({})\n",
    "df6i['Date']=date6i[:1]\n",
    "df6i['Author']=author6i[:1]\n",
    "df6i['Vertical']=vertical6i[:1]\n",
    "df6i['Healines']=headline6i[:1]\n",
    "df6i['Description']=description6i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74be9a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974476b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "bc36ec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "date7=[]\n",
    "author7=[]\n",
    "vertical7=[]\n",
    "headline7=[]\n",
    "description7=[]\n",
    "\n",
    "# scrapping details 7 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date7.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author7.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical7.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline7.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description7.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8cf834fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7=pd.DataFrame({})\n",
    "df7['Date']=date7[:1]\n",
    "df7['Author']=author7[:1]\n",
    "df7['Vertical']=vertical7[:1]\n",
    "df7['Healines']=headline7[:1]\n",
    "df7['Description']=description7[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489363ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "80988562",
   "metadata": {},
   "outputs": [],
   "source": [
    "date7a=[]\n",
    "author7a=[]\n",
    "vertical7a=[]\n",
    "headline7a=[]\n",
    "description7a=[]\n",
    "\n",
    "# scrapping details 7 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date7a.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author7a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical7a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline7a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description7a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "6fba83d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7a=pd.DataFrame({})\n",
    "df7a['Date']=date7a[:1]\n",
    "df7a['Author']=author7a[:1]\n",
    "df7a['Vertical']=vertical7a[:1]\n",
    "df7a['Healines']=headline7a[:1]\n",
    "df7a['Description']=description7a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee78e7a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "15293eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "date7b=[]\n",
    "author7b=[]\n",
    "vertical7b=[]\n",
    "headline7b=[]\n",
    "description7b=[]\n",
    "\n",
    "# scrapping details 7 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date7b.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author7b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical7b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline7b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description7b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "c7826e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7b=pd.DataFrame({})\n",
    "df7b['Date']=date7b[:1]\n",
    "df7b['Author']=author7b[:1]\n",
    "df7b['Vertical']=vertical7b[:1]\n",
    "df7b['Healines']=headline7b[:1]\n",
    "df7b['Description']=description7b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89221602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "ce96d8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "date7c=[]\n",
    "author7c=[]\n",
    "vertical7c=[]\n",
    "headline7c=[]\n",
    "description7c=[]\n",
    "\n",
    "# scrapping details 7 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date7c.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author7c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical7c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline7c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description7c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "52b4f643",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7c=pd.DataFrame({})\n",
    "df7c['Date']=date7c[:1]\n",
    "df7c['Author']=author7c[:1]\n",
    "df7c['Vertical']=vertical7c[:1]\n",
    "df7c['Healines']=headline7c[:1]\n",
    "df7c['Description']=description7c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97d457e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "e83c2734",
   "metadata": {},
   "outputs": [],
   "source": [
    "date7d=[]\n",
    "author7d=[]\n",
    "vertical7d=[]\n",
    "headline7d=[]\n",
    "description7d=[]\n",
    "\n",
    "# scrapping details 7 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date7d.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author7d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical7d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline7d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description7d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "9e9917f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7d=pd.DataFrame({})\n",
    "df7d['Date']=date7d[:1]\n",
    "df7d['Author']=author7d[:1]\n",
    "df7d['Vertical']=vertical7d[:1]\n",
    "df7d['Healines']=headline7d[:1]\n",
    "df7d['Description']=description7d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a37c86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b7adca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date7e=[]\n",
    "author7e=[]\n",
    "vertical7e=[]\n",
    "headline7e=[]\n",
    "description7e=[]\n",
    "\n",
    "# scrapping details 7 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date7e.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author7e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical7e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline7e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description7e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e16a9ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7e=pd.DataFrame({})\n",
    "df7e['Date']=date7e[:1]\n",
    "df7e['Author']=author7e[:1]\n",
    "df7e['Vertical']=vertical7e[:1]\n",
    "df7e['Healines']=headline7e[:1]\n",
    "df7e['Description']=description7e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b102746e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "fcd66583",
   "metadata": {},
   "outputs": [],
   "source": [
    "date7f=[]\n",
    "author7f=[]\n",
    "vertical7f=[]\n",
    "headline7f=[]\n",
    "description7f=[]\n",
    "\n",
    "# scrapping details 7 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date7f.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author7f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical7f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline7f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description7f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "850b797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7f=pd.DataFrame({})\n",
    "df7f['Date']=date7f[:1]\n",
    "df7f['Author']=author7f[:1]\n",
    "df7f['Vertical']=vertical7f[:1]\n",
    "df7f['Healines']=headline7f[:1]\n",
    "df7f['Description']=description7f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0773685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "e6ac784a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date7g=[]\n",
    "author7g=[]\n",
    "vertical7g=[]\n",
    "headline7g=[]\n",
    "description7g=[]\n",
    "\n",
    "# scrapping details 7 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date7g.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author7g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical7g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline7g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description7g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "7c6e09fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7g=pd.DataFrame({})\n",
    "df7g['Date']=date7g[:1]\n",
    "df7g['Author']=author7g[:1]\n",
    "df7g['Vertical']=vertical7g[:1]\n",
    "df7g['Healines']=headline7g[:1]\n",
    "df7g['Description']=description7g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba07381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "4afe5f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "date7h=[]\n",
    "author7h=[]\n",
    "vertical7h=[]\n",
    "headline7h=[]\n",
    "description7h=[]\n",
    "\n",
    "# scrapping details 7 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date7h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author7h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical7h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline7h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description7h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "2a653612",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7h=pd.DataFrame({})\n",
    "df7h['Date']=date7h[:1]\n",
    "df7h['Author']=author7h[:1]\n",
    "df7h['Vertical']=vertical7h[:1]\n",
    "df7h['Healines']=headline7h[:1]\n",
    "df7h['Description']=description7h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71057a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "4711046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "date7i=[]\n",
    "author7i=[]\n",
    "vertical7i=[]\n",
    "headline7i=[]\n",
    "description7i=[]\n",
    "\n",
    "# scrapping details 7 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date7i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author7i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical7i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline7i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description7i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "e284d2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7i=pd.DataFrame({})\n",
    "df7i['Date']=date7i[:1]\n",
    "df7i['Author']=author7i[:1]\n",
    "df7i['Vertical']=vertical7i[:1]\n",
    "df7i['Healines']=headline7i[:1]\n",
    "df7i['Description']=description7i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6c5bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef3dda6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "5bdb52b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "date8=[]\n",
    "author8=[]\n",
    "vertical8=[]\n",
    "headline8=[]\n",
    "description8=[]\n",
    "\n",
    "# scrapping details 8 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date8.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author8.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical8.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline8.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description8.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "5e69c7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8=pd.DataFrame({})\n",
    "df8['Date']=date8[:1]\n",
    "df8['Author']=author8[:1]\n",
    "df8['Vertical']=vertical8[:1]\n",
    "df8['Healines']=headline8[:1]\n",
    "df8['Description']=description8[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a571abc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "b48be7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "date8a=[]\n",
    "author8a=[]\n",
    "vertical8a=[]\n",
    "headline8a=[]\n",
    "description8a=[]\n",
    "\n",
    "# scrapping details 8 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date8a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author8a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical8a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline8a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description8a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "c99bce4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8a=pd.DataFrame({})\n",
    "df8a['Date']=date8a[:1]\n",
    "df8a['Author']=author8a[:1]\n",
    "df8a['Vertical']=vertical8a[:1]\n",
    "df8a['Healines']=headline8a[:1]\n",
    "df8a['Description']=description8a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75fece0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "7ff78c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "date8b=[]\n",
    "author8b=[]\n",
    "vertical8b=[]\n",
    "headline8b=[]\n",
    "description8b=[]\n",
    "\n",
    "# scrapping details 8 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date8b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author8b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical8b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline8b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description8b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "afdeb15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8b=pd.DataFrame({})\n",
    "df8b['Date']=date8b[:1]\n",
    "df8b['Author']=author8b[:1]\n",
    "df8b['Vertical']=vertical8b[:1]\n",
    "df8b['Healines']=headline8b[:1]\n",
    "df8b['Description']=description8b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb10021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "c7e0c414",
   "metadata": {},
   "outputs": [],
   "source": [
    "date8c=[]\n",
    "author8c=[]\n",
    "vertical8c=[]\n",
    "headline8c=[]\n",
    "description8c=[]\n",
    "\n",
    "# scrapping details 8 May 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date8c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author8c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical8c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline8c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description8c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "ad1a70ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8c=pd.DataFrame({})\n",
    "df8c['Date']=date8c[:1]\n",
    "df8c['Author']=author8c[:1]\n",
    "df8c['Vertical']=vertical8c[:1]\n",
    "df8c['Healines']=headline8c[:1]\n",
    "df8c['Description']=description8c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed2ee01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "520bcdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "date8d=[]\n",
    "author8d=[]\n",
    "vertical8d=[]\n",
    "headline8d=[]\n",
    "description8d=[]\n",
    "\n",
    "# scrapping details 8 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date8d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author8d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical8d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline8d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description8d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "23d54a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8d=pd.DataFrame({})\n",
    "df8d['Date']=date8d[:1]\n",
    "df8d['Author']=author8d[:1]\n",
    "df8d['Vertical']=vertical8d[:1]\n",
    "df8d['Healines']=headline8d[:1]\n",
    "df8d['Description']=description8d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1026bbc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "c0976331",
   "metadata": {},
   "outputs": [],
   "source": [
    "date8e=[]\n",
    "author8e=[]\n",
    "vertical8e=[]\n",
    "headline8e=[]\n",
    "description8e=[]\n",
    "\n",
    "# scrapping details 8 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date8e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author8e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical8e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline8e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description8e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "a1986bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8e=pd.DataFrame({})\n",
    "df8e['Date']=date8e[:1]\n",
    "df8e['Author']=author8e[:1]\n",
    "df8e['Vertical']=vertical8e[:1]\n",
    "df8e['Healines']=headline8e[:1]\n",
    "df8e['Description']=description8e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73fa22e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "7d032f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "date8f=[]\n",
    "author8f=[]\n",
    "vertical8f=[]\n",
    "headline8f=[]\n",
    "description8f=[]\n",
    "\n",
    "# scrapping details 8 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date8f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author8f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical8f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline8f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description8f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "0ab10110",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8f=pd.DataFrame({})\n",
    "df8f['Date']=date8f[:1]\n",
    "df8f['Author']=author8f[:1]\n",
    "df8f['Vertical']=vertical8f[:1]\n",
    "df8f['Healines']=headline8f[:1]\n",
    "df8f['Description']=description8f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33e618b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "4e90f0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "date8g=[]\n",
    "author8g=[]\n",
    "vertical8g=[]\n",
    "headline8g=[]\n",
    "description8g=[]\n",
    "\n",
    "# scrapping details 8 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date8g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author8g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical8g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline8g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description8g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "c8efba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8g=pd.DataFrame({})\n",
    "df8g['Date']=date8g[:1]\n",
    "df8g['Author']=author8g[:1]\n",
    "df8g['Vertical']=vertical8g[:1]\n",
    "df8g['Healines']=headline8g[:1]\n",
    "df8g['Description']=description8g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42296cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "b40f8156",
   "metadata": {},
   "outputs": [],
   "source": [
    "date8h=[]\n",
    "author8h=[]\n",
    "vertical8h=[]\n",
    "headline8h=[]\n",
    "description8h=[]\n",
    "\n",
    "# scrapping details 8 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date8h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author8h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical8h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline8h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description8h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "c3fa9d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8h=pd.DataFrame({})\n",
    "df8h['Date']=date8h[:1]\n",
    "df8h['Author']=author8h[:1]\n",
    "df8h['Vertical']=vertical8h[:1]\n",
    "df8h['Healines']=headline8h[:1]\n",
    "df8h['Description']=description8h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59e599d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "5ebcab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "date8i=[]\n",
    "author8i=[]\n",
    "vertical8i=[]\n",
    "headline8i=[]\n",
    "description8i=[]\n",
    "\n",
    "# scrapping details 8 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date8i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author8i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical8i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline8i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description8i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "fb4234d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8i=pd.DataFrame({})\n",
    "df8i['Date']=date8i[:1]\n",
    "df8i['Author']=author8i[:1]\n",
    "df8i['Vertical']=vertical8i[:1]\n",
    "df8i['Healines']=headline8i[:1]\n",
    "df8i['Description']=description8i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b523ffb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff13bd6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "16065030",
   "metadata": {},
   "outputs": [],
   "source": [
    "date9=[]\n",
    "author9=[]\n",
    "vertical9=[]\n",
    "headline9=[]\n",
    "description9=[]\n",
    "\n",
    "# scrapping details 9 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date9.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author9.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical9.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline9.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description9.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "333d548b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9=pd.DataFrame({})\n",
    "df9['Date']=date9[:1]\n",
    "df9['Author']=author9[:1]\n",
    "df9['Vertical']=vertical9[:1]\n",
    "df9['Healines']=headline9[:1]\n",
    "df9['Description']=description9[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9b6c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "29ad084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "date9a=[]\n",
    "author9a=[]\n",
    "vertical9a=[]\n",
    "headline9a=[]\n",
    "description9a=[]\n",
    "\n",
    "# scrapping details 9 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date9a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author9a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical9a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline9a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description9a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "d1f2f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9a=pd.DataFrame({})\n",
    "df9a['Date']=date9a[:1]\n",
    "df9a['Author']=author9a[:1]\n",
    "df9a['Vertical']=vertical9a[:1]\n",
    "df9a['Healines']=headline9a[:1]\n",
    "df9a['Description']=description9a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb35534e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "3200bdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "date9b=[]\n",
    "author9b=[]\n",
    "vertical9b=[]\n",
    "headline9b=[]\n",
    "description9b=[]\n",
    "\n",
    "# scrapping details 9 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date9b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author9b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical9b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline9b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description9b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "e9be6a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9b=pd.DataFrame({})\n",
    "df9b['Date']=date9b[:1]\n",
    "df9b['Author']=author9b[:1]\n",
    "df9b['Vertical']=vertical9b[:1]\n",
    "df9b['Healines']=headline9b[:1]\n",
    "df9b['Description']=description9b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975bdac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "04f3be42",
   "metadata": {},
   "outputs": [],
   "source": [
    "date9c=[]\n",
    "author9c=[]\n",
    "vertical9c=[]\n",
    "headline9c=[]\n",
    "description9c=[]\n",
    "\n",
    "# scrapping details 9 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date9c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author9c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical9c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline9c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description9c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "be743758",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9c=pd.DataFrame({})\n",
    "df9c['Date']=date9c[:1]\n",
    "df9c['Author']=author9c[:1]\n",
    "df9c['Vertical']=vertical9c[:1]\n",
    "df9c['Healines']=headline9c[:1]\n",
    "df9c['Description']=description9c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f0ab48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "37c6cff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "date9d=[]\n",
    "author9d=[]\n",
    "vertical9d=[]\n",
    "headline9d=[]\n",
    "description9d=[]\n",
    "\n",
    "# scrapping details 9 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date9d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author9d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical9d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline9d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description9d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "152d759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9d=pd.DataFrame({})\n",
    "df9d['Date']=date9d[:1]\n",
    "df9d['Author']=author9d[:1]\n",
    "df9d['Vertical']=vertical9d[:1]\n",
    "df9d['Healines']=headline9d[:1]\n",
    "df9d['Description']=description9d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8dfd50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "40c89c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "date9e=[]\n",
    "author9e=[]\n",
    "vertical9e=[]\n",
    "headline9e=[]\n",
    "description9e=[]\n",
    "\n",
    "# scrapping details 9 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date9e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author9e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical9e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline9e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description9e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "1d89074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9e=pd.DataFrame({})\n",
    "df9e['Date']=date9e[:1]\n",
    "df9e['Author']=author9e[:1]\n",
    "df9e['Vertical']=vertical9e[:1]\n",
    "df9e['Healines']=headline9e[:1]\n",
    "df9e['Description']=description9e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71144bae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "9ab37499",
   "metadata": {},
   "outputs": [],
   "source": [
    "date9f=[]\n",
    "author9f=[]\n",
    "vertical9f=[]\n",
    "headline9f=[]\n",
    "description9f=[]\n",
    "\n",
    "# scrapping details 9 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date9f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author9f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='section-container']\")\n",
    "for i in ve:\n",
    "    vertical9f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline9f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description9f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "f791ae01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9f=pd.DataFrame({})\n",
    "df9f['Date']=date9f[:1]\n",
    "df9f['Author']=author9f[:1]\n",
    "df9f['Vertical']=vertical9f[:1]\n",
    "df9f['Healines']=headline9f[:1]\n",
    "df9f['Description']=description9f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad318fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "bec5494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "date9g=[]\n",
    "author9g=[]\n",
    "vertical9g=[]\n",
    "headline9g=[]\n",
    "description9g=[]\n",
    "\n",
    "# scrapping details 9 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date9g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author9g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical9g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline9g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description9g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "fe27d3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9g=pd.DataFrame({})\n",
    "df9g['Date']=date9g[:1]\n",
    "df9g['Author']=author9g[:1]\n",
    "df9g['Vertical']=vertical9g[:1]\n",
    "df9g['Healines']=headline9g[:1]\n",
    "df9g['Description']=description9g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be232bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "4e2726e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "date9h=[]\n",
    "author9h=[]\n",
    "vertical9h=[]\n",
    "headline9h=[]\n",
    "description9h=[]\n",
    "\n",
    "# scrapping details 9 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date9h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author9h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical9h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline9h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description9h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "471b2e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9h=pd.DataFrame({})\n",
    "df9h['Date']=date9h[:1]\n",
    "df9h['Author']=author9h[:1]\n",
    "df9h['Vertical']=vertical9h[:1]\n",
    "df9h['Healines']=headline9h[:1]\n",
    "df9h['Description']=description9h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abfaf30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "e119048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date9i=[]\n",
    "author9i=[]\n",
    "vertical9i=[]\n",
    "headline9i=[]\n",
    "description9i=[]\n",
    "\n",
    "# scrapping details 9 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date9i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author9i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical9i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline9i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description9i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "af49d699",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9i=pd.DataFrame({})\n",
    "df9i['Date']=date9i[:1]\n",
    "df9i['Author']=author9i[:1]\n",
    "df9i['Vertical']=vertical9i[:1]\n",
    "df9i['Healines']=headline9i[:1]\n",
    "df9i['Description']=description9i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c8aa3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a90765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "13d46c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "date10=[]\n",
    "author10=[]\n",
    "vertical10=[]\n",
    "headline10=[]\n",
    "description10=[]\n",
    "\n",
    "# scrapping details 10 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date10.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author10.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical10.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline10.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description10.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "a7deb4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df10=pd.DataFrame({})\n",
    "df10['Date']=date10[:1]\n",
    "df10['Author']=author10[:1]\n",
    "df10['Vertical']=vertical10[:1]\n",
    "df10['Healines']=headline10[:1]\n",
    "df10['Description']=description10[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fcf485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "3a8ac1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "date10a=[]\n",
    "author10a=[]\n",
    "vertical10a=[]\n",
    "headline10a=[]\n",
    "description10a=[]\n",
    "\n",
    "# scrapping details 10 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date10a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author10a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical10a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline10a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description10a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "de188b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df10a=pd.DataFrame({})\n",
    "df10a['Date']=date10a[:1]\n",
    "df10a['Author']=author10a[:1]\n",
    "df10a['Vertical']=vertical10a[:1]\n",
    "df10a['Healines']=headline10a[:1]\n",
    "df10a['Description']=description10a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b19af4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "65eb861f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date10b=[]\n",
    "author10b=[]\n",
    "vertical10b=[]\n",
    "headline10b=[]\n",
    "description10b=[]\n",
    "\n",
    "# scrapping details 10 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date10b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author10b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical10b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline10b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description10b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "ab66f7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df10b=pd.DataFrame({})\n",
    "df10b['Date']=date10b[:1]\n",
    "df10b['Author']=author10b[:1]\n",
    "df10b['Vertical']=vertical10b[:1]\n",
    "df10b['Healines']=headline10b[:1]\n",
    "df10b['Description']=description10b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f319c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "cbfb3b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "date10c=[]\n",
    "author10c=[]\n",
    "vertical10c=[]\n",
    "headline10c=[]\n",
    "description10c=[]\n",
    "\n",
    "# scrapping details 10 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date10c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author10c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical10c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline10c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description10c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "b7201ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df10c=pd.DataFrame({})\n",
    "df10c['Date']=date10c[:1]\n",
    "df10c['Author']=author10c[:1]\n",
    "df10c['Vertical']=vertical10c[:1]\n",
    "df10c['Healines']=headline10c[:1]\n",
    "df10c['Description']=description10c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0bf7dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "cf9ee85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "date10d=[]\n",
    "author10d=[]\n",
    "vertical10d=[]\n",
    "headline10d=[]\n",
    "description10d=[]\n",
    "\n",
    "# scrapping details 10 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date10d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author10d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical10d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline10d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description10d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "4a972eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df10d=pd.DataFrame({})\n",
    "df10d['Date']=date10d[:1]\n",
    "df10d['Author']=author10d[:1]\n",
    "df10d['Vertical']=vertical10d[:1]\n",
    "df10d['Healines']=headline10d[:1]\n",
    "df10d['Description']=description10d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137bf15d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "228706d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "date10e=[]\n",
    "author10e=[]\n",
    "vertical10e=[]\n",
    "headline10e=[]\n",
    "description10e=[]\n",
    "\n",
    "# scrapping details 10 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date10e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author10e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical10e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline10e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description10e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "ade3dec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df10e=pd.DataFrame({})\n",
    "df10e['Date']=date10e[:1]\n",
    "df10e['Author']=author10e[:1]\n",
    "df10e['Vertical']=vertical10e[:1]\n",
    "df10e['Healines']=headline10e[:1]\n",
    "df10e['Description']=description10e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9c5372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "f765cef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "date10f=[]\n",
    "author10f=[]\n",
    "vertical10f=[]\n",
    "headline10f=[]\n",
    "description10f=[]\n",
    "\n",
    "# scrapping details 10 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date10f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author10f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical10f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline10f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description10f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "ad1808d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df10f=pd.DataFrame({})\n",
    "df10f['Date']=date10f[:1]\n",
    "df10f['Author']=author10f[:1]\n",
    "df10f['Vertical']=vertical10f[:1]\n",
    "df10f['Healines']=headline10f[:1]\n",
    "df10f['Description']=description10f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ae225d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "476a4573",
   "metadata": {},
   "outputs": [],
   "source": [
    "date10g=[]\n",
    "author10g=[]\n",
    "vertical10g=[]\n",
    "headline10g=[]\n",
    "description10g=[]\n",
    "\n",
    "# scrapping details 10 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date10g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author10g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical10g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline10g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description10g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "81a12b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df10g=pd.DataFrame({})\n",
    "df10g['Date']=date10g[:1]\n",
    "df10g['Author']=author10g[:1]\n",
    "df10g['Vertical']=vertical10g[:1]\n",
    "df10g['Healines']=headline10g[:1]\n",
    "df10g['Description']=description10g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c720130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "bc43746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "date10h=[]\n",
    "author10h=[]\n",
    "vertical10h=[]\n",
    "headline10h=[]\n",
    "description10h=[]\n",
    "\n",
    "# scrapping details 10 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date10h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author10h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical10h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline10h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description10h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "73b30244",
   "metadata": {},
   "outputs": [],
   "source": [
    "df10h=pd.DataFrame({})\n",
    "df10h['Date']=date10h[:1]\n",
    "df10h['Author']=author10h[:1]\n",
    "df10h['Vertical']=vertical10h[:1]\n",
    "df10h['Healines']=headline10h[:1]\n",
    "df10h['Description']=description10h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ead3947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "f63333a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "date10i=[]\n",
    "author10i=[]\n",
    "vertical10i=[]\n",
    "headline10i=[]\n",
    "description10i=[]\n",
    "\n",
    "# scrapping details 10 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date10i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author10i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical10i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline10i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description10i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "cd8a7865",
   "metadata": {},
   "outputs": [],
   "source": [
    "df10i=pd.DataFrame({})\n",
    "df10i['Date']=date10i[:1]\n",
    "df10i['Author']=author10i[:1]\n",
    "df10i['Vertical']=vertical10i[:1]\n",
    "df10i['Healines']=headline10i[:1]\n",
    "df10i['Description']=description10i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44d489e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fc6e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "5aa485af",
   "metadata": {},
   "outputs": [],
   "source": [
    "date11=[]\n",
    "author11=[]\n",
    "vertical11=[]\n",
    "headline11=[]\n",
    "description11=[]\n",
    "\n",
    "# scrapping details 11 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date11.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author11.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical11.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline11.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description11.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "00cda340",
   "metadata": {},
   "outputs": [],
   "source": [
    "df11=pd.DataFrame({})\n",
    "df11['Date']=date11[:1]\n",
    "df11['Author']=author11[:1]\n",
    "df11['Vertical']=vertical11[:1]\n",
    "df11['Healines']=headline11[:1]\n",
    "df11['Description']=description11[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76efa5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "fa592a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "date11a=[]\n",
    "author11a=[]\n",
    "vertical11a=[]\n",
    "headline11a=[]\n",
    "description11a=[]\n",
    "\n",
    "# scrapping details 11 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date11a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author11a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical11a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline11a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description11a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "b3555e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df11a=pd.DataFrame({})\n",
    "df11a['Date']=date11a[:1]\n",
    "df11a['Author']=author11a[:1]\n",
    "df11a['Vertical']=vertical11a[:1]\n",
    "df11a['Healines']=headline11a[:1]\n",
    "df11a['Description']=description11a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c6f431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "1d3555b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "date11b=[]\n",
    "author11b=[]\n",
    "vertical11b=[]\n",
    "headline11b=[]\n",
    "description11b=[]\n",
    "\n",
    "# scrapping details 11 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date11b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author11b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical11b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline11b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description11b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "4f358e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df11b=pd.DataFrame({})\n",
    "df11b['Date']=date11b[:1]\n",
    "df11b['Author']=author11b[:1]\n",
    "df11b['Vertical']=vertical11b[:1]\n",
    "df11b['Healines']=headline11b[:1]\n",
    "df11b['Description']=description11b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1654c447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "39cc406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "date11c=[]\n",
    "author11c=[]\n",
    "vertical11c=[]\n",
    "headline11c=[]\n",
    "description11c=[]\n",
    "\n",
    "# scrapping details 11 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date11c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author11c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical11c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline11c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description11c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "9afe435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df11c=pd.DataFrame({})\n",
    "df11c['Date']=date11c[:1]\n",
    "df11c['Author']=author11c[:1]\n",
    "df11c['Vertical']=vertical11c[:1]\n",
    "df11c['Healines']=headline11c[:1]\n",
    "df11c['Description']=description11c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38529997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "0d0e07be",
   "metadata": {},
   "outputs": [],
   "source": [
    "date11d=[]\n",
    "author11d=[]\n",
    "vertical11d=[]\n",
    "headline11d=[]\n",
    "description11d=[]\n",
    "\n",
    "# scrapping details 11 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date11d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author11d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical11d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline11d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description11d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "8ffdfdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df11d=pd.DataFrame({})\n",
    "df11d['Date']=date11d[:1]\n",
    "df11d['Author']=author11d[:1]\n",
    "df11d['Vertical']=vertical11d[:1]\n",
    "df11d['Healines']=headline11d[:1]\n",
    "df11d['Description']=description11d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d7a12b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "3144bc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "date11e=[]\n",
    "author11e=[]\n",
    "vertical11e=[]\n",
    "headline11e=[]\n",
    "description11e=[]\n",
    "\n",
    "# scrapping details 11 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date11e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author11e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical11e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline11e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description11e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "f6037572",
   "metadata": {},
   "outputs": [],
   "source": [
    "df11e=pd.DataFrame({})\n",
    "df11e['Date']=date11e[:1]\n",
    "df11e['Author']=author11e[:1]\n",
    "df11e['Vertical']=vertical11e[:1]\n",
    "df11e['Healines']=headline11e[:1]\n",
    "df11e['Description']=description11e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff48aac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "92788704",
   "metadata": {},
   "outputs": [],
   "source": [
    "date11f=[]\n",
    "author11f=[]\n",
    "vertical11f=[]\n",
    "headline11f=[]\n",
    "description11f=[]\n",
    "\n",
    "# scrapping details 11 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date11f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author11f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical11f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline11f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description11f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "b2e4004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df11f=pd.DataFrame({})\n",
    "df11f['Date']=date11f[:1]\n",
    "df11f['Author']=author11f[:1]\n",
    "df11f['Vertical']=vertical11f[:1]\n",
    "df11f['Healines']=headline11f[:1]\n",
    "df11f['Description']=description11f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa91bad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "7ee60f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "date11g=[]\n",
    "author11g=[]\n",
    "vertical11g=[]\n",
    "headline11g=[]\n",
    "description11g=[]\n",
    "\n",
    "# scrapping details 11 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date11g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author11g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical11g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline11g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description11g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "2881d7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df11g=pd.DataFrame({})\n",
    "df11g['Date']=date11g[:1]\n",
    "df11g['Author']=author11g[:1]\n",
    "df11g['Vertical']=vertical11g[:1]\n",
    "df11g['Healines']=headline11g[:1]\n",
    "df11g['Description']=description11g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135ada1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "e5f6751a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date11h=[]\n",
    "author11h=[]\n",
    "vertical11h=[]\n",
    "headline11h=[]\n",
    "description11h=[]\n",
    "\n",
    "# scrapping details 11 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date11h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author11h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical11h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline11h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description11h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "4c269fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df11h=pd.DataFrame({})\n",
    "df11h['Date']=date11h[:1]\n",
    "df11h['Author']=author11h[:1]\n",
    "df11h['Vertical']=vertical11h[:1]\n",
    "df11h['Healines']=headline11h[:1]\n",
    "df11h['Description']=description11h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f0dcb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "d82dc4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "date11i=[]\n",
    "author11i=[]\n",
    "vertical11i=[]\n",
    "headline11i=[]\n",
    "description11i=[]\n",
    "\n",
    "# scrapping details 11 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date11i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author11i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical11i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline11i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description11i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "baede3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df11i=pd.DataFrame({})\n",
    "df11i['Date']=date11i[:1]\n",
    "df11i['Author']=author11i[:1]\n",
    "df11i['Vertical']=vertical11i[:1]\n",
    "df11i['Healines']=headline11i[:1]\n",
    "df11i['Description']=description11i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c6b55a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd4693c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "fbb4d74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "date12=[]\n",
    "author12=[]\n",
    "vertical12=[]\n",
    "headline12=[]\n",
    "description12=[]\n",
    "\n",
    "# scrapping details 12 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date12.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author12.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical12.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline12.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description12.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "66add1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12=pd.DataFrame({})\n",
    "df12['Date']=date12[:1]\n",
    "df12['Author']=author12[:1]\n",
    "df12['Vertical']=vertical12[:1]\n",
    "df12['Healines']=headline12[:1]\n",
    "df12['Description']=description12[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d45b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "cab913ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "date12a=[]\n",
    "author12a=[]\n",
    "vertical12a=[]\n",
    "headline12a=[]\n",
    "description12a=[]\n",
    "\n",
    "# scrapping details 12 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date12a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author12a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical12a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline12a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description12a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "f8eb3979",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12a=pd.DataFrame({})\n",
    "df12a['Date']=date12a[:1]\n",
    "df12a['Author']=author12a[:1]\n",
    "df12a['Vertical']=vertical12a[:1]\n",
    "df12a['Healines']=headline12a[:1]\n",
    "df12a['Description']=description12a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703d358c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "76a591df",
   "metadata": {},
   "outputs": [],
   "source": [
    "date12b=[]\n",
    "author12b=[]\n",
    "vertical12b=[]\n",
    "headline12b=[]\n",
    "description12b=[]\n",
    "\n",
    "# scrapping details 12 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date12b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author12b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical12b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline12b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description12b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "429cd031",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12b=pd.DataFrame({})\n",
    "df12b['Date']=date12b[:1]\n",
    "df12b['Author']=author12b[:1]\n",
    "df12b['Vertical']=vertical12b[:1]\n",
    "df12b['Healines']=headline12b[:1]\n",
    "df12b['Description']=description12b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf09fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "e9630d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "date12c=[]\n",
    "author12c=[]\n",
    "vertical12c=[]\n",
    "headline12c=[]\n",
    "description12c=[]\n",
    "\n",
    "# scrapping details 12 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date12c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author12c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical12c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline12c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description12c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "0b1b5a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12c=pd.DataFrame({})\n",
    "df12c['Date']=date12c[:1]\n",
    "df12c['Author']=author12c[:1]\n",
    "df12c['Vertical']=vertical12c[:1]\n",
    "df12c['Healines']=headline12c[:1]\n",
    "df12c['Description']=description12c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1dfb74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "4a0afe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "date12d=[]\n",
    "author12d=[]\n",
    "vertical12d=[]\n",
    "headline12d=[]\n",
    "description12d=[]\n",
    "\n",
    "# scrapping details 12 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date12d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author12d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical12d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline12d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description12d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "42a46f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12d=pd.DataFrame({})\n",
    "df12d['Date']=date12d[:1]\n",
    "df12d['Author']=author12d[:1]\n",
    "df12d['Vertical']=vertical12d[:1]\n",
    "df12d['Healines']=headline12d[:1]\n",
    "df12d['Description']=description12d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c4a23e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "b93d5aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "date12e=[]\n",
    "author12e=[]\n",
    "vertical12e=[]\n",
    "headline12e=[]\n",
    "description12e=[]\n",
    "\n",
    "# scrapping details 12 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date12e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author12e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical12e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline12e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description12e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "59ab55e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12e=pd.DataFrame({})\n",
    "df12e['Date']=date12e[:1]\n",
    "df12e['Author']=author12e[:1]\n",
    "df12e['Vertical']=vertical12e[:1]\n",
    "df12e['Healines']=headline12e[:1]\n",
    "df12e['Description']=description12e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9256979a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "e54f3e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "date12f=[]\n",
    "author12f=[]\n",
    "vertical12f=[]\n",
    "headline12f=[]\n",
    "description12f=[]\n",
    "\n",
    "# scrapping details 12 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date12f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author12f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical12f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline12f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description12f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "d00e447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12f=pd.DataFrame({})\n",
    "df12f['Date']=date12f[:1]\n",
    "df12f['Author']=author12f[:1]\n",
    "df12f['Vertical']=vertical12f[:1]\n",
    "df12f['Healines']=headline12f[:1]\n",
    "df12f['Description']=description12f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea5f32d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "675eec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "date12g=[]\n",
    "author12g=[]\n",
    "vertical12g=[]\n",
    "headline12g=[]\n",
    "description12g=[]\n",
    "\n",
    "# scrapping details 12 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date12g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author12g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical12g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline12g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description12g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "8289bfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12g=pd.DataFrame({})\n",
    "df12g['Date']=date12g[:1]\n",
    "df12g['Author']=author12g[:1]\n",
    "df12g['Vertical']=vertical12g[:1]\n",
    "df12g['Healines']=headline12g[:1]\n",
    "df12g['Description']=description12g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399792e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "1304cd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "date12h=[]\n",
    "author12h=[]\n",
    "vertical12h=[]\n",
    "headline12h=[]\n",
    "description12h=[]\n",
    "\n",
    "# scrapping details 12 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date12h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author12h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical12h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline12h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description12h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "e6634b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12h=pd.DataFrame({})\n",
    "df12h['Date']=date12h[:1]\n",
    "df12h['Author']=author12h[:1]\n",
    "df12h['Vertical']=vertical12h[:1]\n",
    "df12h['Healines']=headline12h[:1]\n",
    "df12h['Description']=description12h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47091777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "1b75801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "date12i=[]\n",
    "author12i=[]\n",
    "vertical12i=[]\n",
    "headline12i=[]\n",
    "description12i=[]\n",
    "\n",
    "# scrapping details 12 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date12i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author12i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical12i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline12i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description12i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "3315e1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12i=pd.DataFrame({})\n",
    "df12i['Date']=date12i[:1]\n",
    "df12i['Author']=author12i[:1]\n",
    "df12i['Vertical']=vertical12i[:1]\n",
    "df12i['Healines']=headline12i[:1]\n",
    "df12i['Description']=description12i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54f8590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643eb498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "c0ad414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "date13=[]\n",
    "author13=[]\n",
    "vertical13=[]\n",
    "headline13=[]\n",
    "description13=[]\n",
    "\n",
    "# scrapping details 13 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date13.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author13.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical13.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline13.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description13.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "70830ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df13=pd.DataFrame({})\n",
    "df13['Date']=date13[:1]\n",
    "df13['Author']=author13[:1]\n",
    "df13['Vertical']=vertical13[:1]\n",
    "df13['Healines']=headline13[:1]\n",
    "df13['Description']=description13[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acecfd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "adc05663",
   "metadata": {},
   "outputs": [],
   "source": [
    "date13a=[]\n",
    "author13a=[]\n",
    "vertical13a=[]\n",
    "headline13a=[]\n",
    "description13a=[]\n",
    "\n",
    "# scrapping details 13 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-reg article-author__name']\")\n",
    "for i in dt:\n",
    "    date13a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author13a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical13a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline13a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description13a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "adc6fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df13a=pd.DataFrame({})\n",
    "df13a['Date']=date13a[:1]\n",
    "df13a['Author']=author13a[:1]\n",
    "df13a['Vertical']=vertical13a[:1]\n",
    "df13a['Healines']=headline13a[:1]\n",
    "df13a['Description']=description13a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f310a4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "7187b63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "date13b=[]\n",
    "author13b=[]\n",
    "vertical13b=[]\n",
    "headline13b=[]\n",
    "description13b=[]\n",
    "\n",
    "# scrapping details 13 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date13b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author13b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical13b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline13b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description13b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "4e4af4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df13b=pd.DataFrame({})\n",
    "df13b['Date']=date13b[:1]\n",
    "df13b['Author']=author13b[:1]\n",
    "df13b['Vertical']=vertical13b[:1]\n",
    "df13b['Healines']=headline13b[:1]\n",
    "df13b['Description']=description13b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12865d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "a1683f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "date13c=[]\n",
    "author13c=[]\n",
    "vertical13c=[]\n",
    "headline13c=[]\n",
    "description13c=[]\n",
    "\n",
    "# scrapping details 13 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date13c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author13c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical13c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline13c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description13c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "a3fc95cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df13c=pd.DataFrame({})\n",
    "df13c['Date']=date13c[:1]\n",
    "df13c['Author']=author13c[:1]\n",
    "df13c['Vertical']=vertical13c[:1]\n",
    "df13c['Healines']=headline13c[:1]\n",
    "df13c['Description']=description13c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a15315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "f0bf1150",
   "metadata": {},
   "outputs": [],
   "source": [
    "date13d=[]\n",
    "author13d=[]\n",
    "vertical13d=[]\n",
    "headline13d=[]\n",
    "description13d=[]\n",
    "\n",
    "# scrapping details 13 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date13d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author13d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical13d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline13d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description13d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "7de52c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df13d=pd.DataFrame({})\n",
    "df13d['Date']=date13d[:1]\n",
    "df13d['Author']=author13d[:1]\n",
    "df13d['Vertical']=vertical13d[:1]\n",
    "df13d['Healines']=headline13d[:1]\n",
    "df13d['Description']=description13d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65493cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "62c54962",
   "metadata": {},
   "outputs": [],
   "source": [
    "date13e=[]\n",
    "author13e=[]\n",
    "vertical13e=[]\n",
    "headline13e=[]\n",
    "description13e=[]\n",
    "\n",
    "# scrapping details 13 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date13e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author13e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical13e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline13e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description13e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "279662e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df13e=pd.DataFrame({})\n",
    "df13e['Date']=date13e[:1]\n",
    "df13e['Author']=author13e[:1]\n",
    "df13e['Vertical']=vertical13e[:1]\n",
    "df13e['Healines']=headline13e[:1]\n",
    "df13e['Description']=description13e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37f4e5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "f40be9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "date13f=[]\n",
    "author13f=[]\n",
    "vertical13f=[]\n",
    "headline13f=[]\n",
    "description13f=[]\n",
    "\n",
    "# scrapping details 13 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date13f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author13f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical13f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline13f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description13f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "f180a1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df13f=pd.DataFrame({})\n",
    "df13f['Date']=date13f[:1]\n",
    "df13f['Author']=author13f[:1]\n",
    "df13f['Vertical']=vertical13f[:1]\n",
    "df13f['Healines']=headline13f[:1]\n",
    "df13f['Description']=description13f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67158280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "d0a21c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "date13g=[]\n",
    "author13g=[]\n",
    "vertical13g=[]\n",
    "headline13g=[]\n",
    "description13g=[]\n",
    "\n",
    "# scrapping details 13 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date13g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author13g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical13g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline13g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description13g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "1ccc10dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df13g=pd.DataFrame({})\n",
    "df13g['Date']=date13g[:1]\n",
    "df13g['Author']=author13g[:1]\n",
    "df13g['Vertical']=vertical13g[:1]\n",
    "df13g['Healines']=headline13g[:1]\n",
    "df13g['Description']=description13g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6127b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "d9ad91d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "date13h=[]\n",
    "author13h=[]\n",
    "vertical13h=[]\n",
    "headline13h=[]\n",
    "description13h=[]\n",
    "\n",
    "# scrapping details 13 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date13h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author13h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical13h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline13h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description13h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "2c9745ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df13h=pd.DataFrame({})\n",
    "df13h['Date']=date13h[:1]\n",
    "df13h['Author']=author13h[:1]\n",
    "df13h['Vertical']=vertical13h[:1]\n",
    "df13h['Healines']=headline13h[:1]\n",
    "df13h['Description']=description13h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45bc8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "e39dec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "date13i=[]\n",
    "author13i=[]\n",
    "vertical13i=[]\n",
    "headline13i=[]\n",
    "description13i=[]\n",
    "\n",
    "# scrapping details 13 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date13i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author13i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical13i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline13i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description13i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "8f89f96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df13i=pd.DataFrame({})\n",
    "df13i['Date']=date13i[:1]\n",
    "df13i['Author']=author13i[:1]\n",
    "df13i['Vertical']=vertical13i[:1]\n",
    "df13i['Healines']=headline13i[:1]\n",
    "df13i['Description']=description13i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d84285c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1a8254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "46db4c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "date14=[]\n",
    "author14=[]\n",
    "vertical14=[]\n",
    "headline14=[]\n",
    "description14=[]\n",
    "\n",
    "# scrapping details 14 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date14.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author14.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical14.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline14.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description14.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "4f57bea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df14=pd.DataFrame({})\n",
    "df14['Date']=date14[:1]\n",
    "df14['Author']=author14[:1]\n",
    "df14['Vertical']=vertical14[:1]\n",
    "df14['Healines']=headline14[:1]\n",
    "df14['Description']=description14[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e36e193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "11901590",
   "metadata": {},
   "outputs": [],
   "source": [
    "date14a=[]\n",
    "author14a=[]\n",
    "vertical14a=[]\n",
    "headline14a=[]\n",
    "description14a=[]\n",
    "\n",
    "# scrapping details 14 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date14a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author14a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical14a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline14a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description14a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "958972b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df14a=pd.DataFrame({})\n",
    "df14a['Date']=date14a[:1]\n",
    "df14a['Author']=author14a[:1]\n",
    "df14a['Vertical']=vertical14a[:1]\n",
    "df14a['Healines']=headline14a[:1]\n",
    "df14a['Description']=description14a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5a72c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "74ac16c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "date14b=[]\n",
    "author14b=[]\n",
    "vertical14b=[]\n",
    "headline14b=[]\n",
    "description14b=[]\n",
    "\n",
    "# scrapping details 14 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date14b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author14b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical14b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline14b.append(i.text)\n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description14b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "b4e9aa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df14b=pd.DataFrame({})\n",
    "df14b['Date']=date14b[:1]\n",
    "df14b['Author']=author14b[:1]\n",
    "df14b['Vertical']=vertical14b[:1]\n",
    "df14b['Healines']=headline14b[:1]\n",
    "df14b['Description']=description14b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d931c6ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "f2288d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "date14c=[]\n",
    "author14c=[]\n",
    "vertical14c=[]\n",
    "headline14c=[]\n",
    "description14c=[]\n",
    "\n",
    "# scrapping details 14 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date14c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author14c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical14c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline14c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description14c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "5d7342e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df14c=pd.DataFrame({})\n",
    "df14c['Date']=date14c[:1]\n",
    "df14c['Author']=author14c[:1]\n",
    "df14c['Vertical']=vertical14c[:1]\n",
    "df14c['Healines']=headline14c[:1]\n",
    "df14c['Description']=description14c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0eb1c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "1d50d005",
   "metadata": {},
   "outputs": [],
   "source": [
    "date14d=[]\n",
    "author14d=[]\n",
    "vertical14d=[]\n",
    "headline14d=[]\n",
    "description14d=[]\n",
    "\n",
    "# scrapping details 14 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date14d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author14d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical14d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline14d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description14d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "5bdedeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df14d=pd.DataFrame({})\n",
    "df14d['Date']=date14d[:1]\n",
    "df14d['Author']=author14d[:1]\n",
    "df14d['Vertical']=vertical14d[:1]\n",
    "df14d['Healines']=headline14d[:1]\n",
    "df14d['Description']=description14d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a841ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "7c66fddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "date14e=[]\n",
    "author14e=[]\n",
    "vertical14e=[]\n",
    "headline14e=[]\n",
    "description14e=[]\n",
    "\n",
    "# scrapping details 14 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date14e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author14e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical14e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline14e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description14e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "74707235",
   "metadata": {},
   "outputs": [],
   "source": [
    "df14e=pd.DataFrame({})\n",
    "df14e['Date']=date14e[:1]\n",
    "df14e['Author']=author14e[:1]\n",
    "df14e['Vertical']=vertical14e[:1]\n",
    "df14e['Healines']=headline14e[:1]\n",
    "df14e['Description']=description14e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6f3afd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "a38e26d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "date14f=[]\n",
    "author14f=[]\n",
    "vertical14f=[]\n",
    "headline14f=[]\n",
    "description14f=[]\n",
    "\n",
    "# scrapping details 14 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date14f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author14f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical14f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline14f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description14f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "0ef7bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df14f=pd.DataFrame({})\n",
    "df14f['Date']=date14f[:1]\n",
    "df14f['Author']=author14f[:1]\n",
    "df14f['Vertical']=vertical14f[:1]\n",
    "df14f['Healines']=headline14f[:1]\n",
    "df14f['Description']=description14f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8616aa55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "f0a49ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "date14g=[]\n",
    "author14g=[]\n",
    "vertical14g=[]\n",
    "headline14g=[]\n",
    "description14g=[]\n",
    "\n",
    "# scrapping details 14 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date14g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author14g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical14g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline14g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description14g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "fb824ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df14g=pd.DataFrame({})\n",
    "df14g['Date']=date14g[:1]\n",
    "df14g['Author']=author14g[:1]\n",
    "df14g['Vertical']=vertical14g[:1]\n",
    "df14g['Healines']=headline14g[:1]\n",
    "df14g['Description']=description14g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949fa1a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "ffe4c6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "date14h=[]\n",
    "author14h=[]\n",
    "vertical14h=[]\n",
    "headline14h=[]\n",
    "description14h=[]\n",
    "\n",
    "# scrapping details 14 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date14h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author14h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical14h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline14h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description14h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "431ed0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df14h=pd.DataFrame({})\n",
    "df14h['Date']=date14h[:1]\n",
    "df14h['Author']=author14h[:1]\n",
    "df14h['Vertical']=vertical14h[:1]\n",
    "df14h['Healines']=headline14h[:1]\n",
    "df14h['Description']=description14h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b775d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "db1d7834",
   "metadata": {},
   "outputs": [],
   "source": [
    "date14i=[]\n",
    "author14i=[]\n",
    "vertical14i=[]\n",
    "headline14i=[]\n",
    "description14i=[]\n",
    "\n",
    "# scrapping details 14 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date14i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author14i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical14i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline14i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description14i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "5efa751a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df14i=pd.DataFrame({})\n",
    "df14i['Date']=date14i[:1]\n",
    "df14i['Author']=author14i[:1]\n",
    "df14i['Vertical']=vertical14i[:1]\n",
    "df14i['Healines']=headline14i[:1]\n",
    "df14i['Description']=description14i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd6a291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5df13c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "de5353b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "date15=[]\n",
    "author15=[]\n",
    "vertical15=[]\n",
    "headline15=[]\n",
    "description15=[]\n",
    "\n",
    "# scrapping details 15 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date15.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author15.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical15.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline15.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description15.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "f16cc282",
   "metadata": {},
   "outputs": [],
   "source": [
    "df15=pd.DataFrame({})\n",
    "df15['Date']=date15[:1]\n",
    "df15['Author']=author15[:1]\n",
    "df15['Vertical']=vertical15[:1]\n",
    "df15['Healines']=headline15[:1]\n",
    "df15['Description']=description15[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62693546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "34825c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "date15a=[]\n",
    "author15a=[]\n",
    "vertical15a=[]\n",
    "headline15a=[]\n",
    "description15a=[]\n",
    "\n",
    "# scrapping details 15 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date15a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author15a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical15a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline15a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description15a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "c280c6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df15a=pd.DataFrame({})\n",
    "df15a['Date']=date15a[:1]\n",
    "df15a['Author']=author15a[:1]\n",
    "df15a['Vertical']=vertical15a[:1]\n",
    "df15a['Healines']=headline15a[:1]\n",
    "df15a['Description']=description15a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cf7be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "bee25d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "date15b=[]\n",
    "author15b=[]\n",
    "vertical15b=[]\n",
    "headline15b=[]\n",
    "description15b=[]\n",
    "\n",
    "# scrapping details 15 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date15b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author15b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical15b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline15b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description15b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "7f869fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df15b=pd.DataFrame({})\n",
    "df15b['Date']=date15b[:1]\n",
    "df15b['Author']=author15b[:1]\n",
    "df15b['Vertical']=vertical15b[:1]\n",
    "df15b['Healines']=headline15b[:1]\n",
    "df15b['Description']=description15b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507e8fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "cc879b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "date15c=[]\n",
    "author15c=[]\n",
    "vertical15c=[]\n",
    "headline15c=[]\n",
    "description15c=[]\n",
    "\n",
    "# scrapping details 15 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date15c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author15c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical15c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline15c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description15c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "f7cd80f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df15c=pd.DataFrame({})\n",
    "df15c['Date']=date15c[:1]\n",
    "df15c['Author']=author15c[:1]\n",
    "df15c['Vertical']=vertical15c[:1]\n",
    "df15c['Healines']=headline15c[:1]\n",
    "df15c['Description']=description15c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed84370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "6b48354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "date15d=[]\n",
    "author15d=[]\n",
    "vertical15d=[]\n",
    "headline15d=[]\n",
    "description15d=[]\n",
    "\n",
    "# scrapping details 15 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date15d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author15d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical15d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline15d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description15d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "a0a5b43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df15d=pd.DataFrame({})\n",
    "df15d['Date']=date15d[:1]\n",
    "df15d['Author']=author15d[:1]\n",
    "df15d['Vertical']=vertical15d[:1]\n",
    "df15d['Healines']=headline15d[:1]\n",
    "df15d['Description']=description15d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28599085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "3500c32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "date15e=[]\n",
    "author15e=[]\n",
    "vertical15e=[]\n",
    "headline15e=[]\n",
    "description15e=[]\n",
    "\n",
    "# scrapping details 15 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date15e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author15e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical15e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline15e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description15e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "d0b38ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df15e=pd.DataFrame({})\n",
    "df15e['Date']=date15e[:1]\n",
    "df15e['Author']=author15e[:1]\n",
    "df15e['Vertical']=vertical15e[:1]\n",
    "df15e['Healines']=headline15e[:1]\n",
    "df15e['Description']=description15[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f72911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "9954d390",
   "metadata": {},
   "outputs": [],
   "source": [
    "date15f=[]\n",
    "author15f=[]\n",
    "vertical15f=[]\n",
    "headline15f=[]\n",
    "description15f=[]\n",
    "\n",
    "# scrapping details 15 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date15f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author15f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical15f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline15f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description15f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "2bf3b042",
   "metadata": {},
   "outputs": [],
   "source": [
    "df15f=pd.DataFrame({})\n",
    "df15f['Date']=date15f[:1]\n",
    "df15f['Author']=author15f[:1]\n",
    "df15f['Vertical']=vertical15f[:1]\n",
    "df15f['Healines']=headline15f[:1]\n",
    "df15f['Description']=description15f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fca4df2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "b63d19fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "date15g=[]\n",
    "author15g=[]\n",
    "vertical15g=[]\n",
    "headline15g=[]\n",
    "description15g=[]\n",
    "\n",
    "# scrapping details 15 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date15g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author15g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical15g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline15g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description15g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "d5e647cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df15g=pd.DataFrame({})\n",
    "df15g['Date']=date15g[:1]\n",
    "df15g['Author']=author15g[:1]\n",
    "df15g['Vertical']=vertical15g[:1]\n",
    "df15g['Healines']=headline15g[:1]\n",
    "df15g['Description']=description15g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e2ee62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "9d218d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "date15h=[]\n",
    "author15h=[]\n",
    "vertical15h=[]\n",
    "headline15h=[]\n",
    "description15h=[]\n",
    "\n",
    "# scrapping details 15 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date15h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author15h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical15h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline15h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description15h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "9640592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df15h=pd.DataFrame({})\n",
    "df15h['Date']=date15h[:1]\n",
    "df15h['Author']=author15h[:1]\n",
    "df15h['Vertical']=vertical15h[:1]\n",
    "df15h['Healines']=headline15h[:1]\n",
    "df15h['Description']=description15h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf374346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "21e187a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "date15i=[]\n",
    "author15i=[]\n",
    "vertical15i=[]\n",
    "headline15i=[]\n",
    "description15i=[]\n",
    "\n",
    "# scrapping details 15 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date15i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author15i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical15i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline15i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description15i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "0b84e82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df15i=pd.DataFrame({})\n",
    "df15i['Date']=date15i[:1]\n",
    "df15i['Author']=author15i[:1]\n",
    "df15i['Vertical']=vertical15i[:1]\n",
    "df15i['Healines']=headline15i[:1]\n",
    "df15i['Description']=description15i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b351cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b3d057",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "723a8a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "date16=[]\n",
    "author16=[]\n",
    "vertical16=[]\n",
    "headline16=[]\n",
    "description16=[]\n",
    "\n",
    "# scrapping details 16 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date16.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author16.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical16.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline16.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description16.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "5a12d2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df16=pd.DataFrame({})\n",
    "df16['Date']=date16[:1]\n",
    "df16['Author']=author16[:1]\n",
    "df16['Vertical']=vertical16[:1]\n",
    "df16['Healines']=headline16[:1]\n",
    "df16['Description']=description16[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b913e516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "cf0c37bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "date16a=[]\n",
    "author16a=[]\n",
    "vertical16a=[]\n",
    "headline16a=[]\n",
    "description16a=[]\n",
    "\n",
    "# scrapping details 16 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date16a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author16a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical16a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline16a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description16a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "c7b28e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df16a=pd.DataFrame({})\n",
    "df16a['Date']=date16a[:1]\n",
    "df16a['Author']=author16a[:1]\n",
    "df16a['Vertical']=vertical16a[:1]\n",
    "df16a['Healines']=headline16a[:1]\n",
    "df16a['Description']=description16a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9270d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "b5aff388",
   "metadata": {},
   "outputs": [],
   "source": [
    "date16b=[]\n",
    "author16b=[]\n",
    "vertical16b=[]\n",
    "headline16b=[]\n",
    "description16b=[]\n",
    "\n",
    "# scrapping details 16 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date16b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author16b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical16b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline16b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description16b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "23e52de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df16b=pd.DataFrame({})\n",
    "df16b['Date']=date16b[:1]\n",
    "df16b['Author']=author16b[:1]\n",
    "df16b['Vertical']=vertical16b[:1]\n",
    "df16b['Healines']=headline16b[:1]\n",
    "df16b['Description']=description16b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42799e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "8c4e540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "date16c=[]\n",
    "author16c=[]\n",
    "vertical16c=[]\n",
    "headline16c=[]\n",
    "description16c=[]\n",
    "\n",
    "# scrapping details 16 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date16c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author16c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical16c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline16c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description16c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "1cda8d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df16c=pd.DataFrame({})\n",
    "df16c['Date']=date16c[:1]\n",
    "df16c['Author']=author16c[:1]\n",
    "df16c['Vertical']=vertical16c[:1]\n",
    "df16c['Healines']=headline16c[:1]\n",
    "df16c['Description']=description16c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f62278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "d2f8e992",
   "metadata": {},
   "outputs": [],
   "source": [
    "date16d=[]\n",
    "author16d=[]\n",
    "vertical16d=[]\n",
    "headline16d=[]\n",
    "description16d=[]\n",
    "\n",
    "# scrapping details 16 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date16d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author16d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical16d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline16d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description16d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "d0b32178",
   "metadata": {},
   "outputs": [],
   "source": [
    "df16d=pd.DataFrame({})\n",
    "df16d['Date']=date16d[:1]\n",
    "df16d['Author']=author16d[:1]\n",
    "df16d['Vertical']=vertical16d[:1]\n",
    "df16d['Healines']=headline16d[:1]\n",
    "df16d['Description']=description16d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5971213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "0cfa2926",
   "metadata": {},
   "outputs": [],
   "source": [
    "date16e=[]\n",
    "author16e=[]\n",
    "vertical16e=[]\n",
    "headline16e=[]\n",
    "description16e=[]\n",
    "\n",
    "# scrapping details 16 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date16e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author16e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical16e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline16e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description16e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "20fde55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df16e=pd.DataFrame({})\n",
    "df16e['Date']=date16e[:1]\n",
    "df16e['Author']=author16e[:1]\n",
    "df16e['Vertical']=vertical16e[:1]\n",
    "df16e['Healines']=headline16e[:1]\n",
    "df16e['Description']=description16e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322f03ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "750b5a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date16f=[]\n",
    "author16f=[]\n",
    "vertical16f=[]\n",
    "headline16f=[]\n",
    "description16f=[]\n",
    "\n",
    "# scrapping details 16 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date16f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author16f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical16f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline16f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description16f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "a9e36124",
   "metadata": {},
   "outputs": [],
   "source": [
    "df16f=pd.DataFrame({})\n",
    "df16f['Date']=date16f[:1]\n",
    "df16f['Author']=author16f[:1]\n",
    "df16f['Vertical']=vertical16f[:1]\n",
    "df16f['Healines']=headline16f[:1]\n",
    "df16f['Description']=description16f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9804185d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "1107c301",
   "metadata": {},
   "outputs": [],
   "source": [
    "date16g=[]\n",
    "author16g=[]\n",
    "vertical16g=[]\n",
    "headline16g=[]\n",
    "description16g=[]\n",
    "\n",
    "# scrapping details 16 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date16g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author16g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical16g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline16g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description16g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "9942b0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df16g=pd.DataFrame({})\n",
    "df16g['Date']=date16g[:1]\n",
    "df16g['Author']=author16g[:1]\n",
    "df16g['Vertical']=vertical16g[:1]\n",
    "df16g['Healines']=headline16g[:1]\n",
    "df16g['Description']=description16g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27e68e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "b5375c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "date16h=[]\n",
    "author16h=[]\n",
    "vertical16h=[]\n",
    "headline16h=[]\n",
    "description16h=[]\n",
    "\n",
    "# scrapping details 16 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date16h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author16h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical16h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline16h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description16h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "bbe80c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df16h=pd.DataFrame({})\n",
    "df16h['Date']=date16h[:1]\n",
    "df16h['Author']=author16h[:1]\n",
    "df16h['Vertical']=vertical16h[:1]\n",
    "df16h['Healines']=headline16h[:1]\n",
    "df16h['Description']=description16h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262f16ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "66f963ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "date16i=[]\n",
    "author16i=[]\n",
    "vertical16i=[]\n",
    "headline16i=[]\n",
    "description16i=[]\n",
    "\n",
    "# scrapping details 16 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date16i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author16i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical16i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline16i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description16i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "5b5e1e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df16i=pd.DataFrame({})\n",
    "df16i['Date']=date16i[:1]\n",
    "df16i['Author']=author16i[:1]\n",
    "df16i['Vertical']=vertical16i[:1]\n",
    "df16i['Healines']=headline16i[:1]\n",
    "df16i['Description']=description16i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b9c591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504cdf4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "3dec152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "date17=[]\n",
    "author17=[]\n",
    "vertical17=[]\n",
    "headline17=[]\n",
    "description17=[]\n",
    "\n",
    "# scrapping details 17 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date17.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author17.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical17.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline17.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description17.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "6b1e7685",
   "metadata": {},
   "outputs": [],
   "source": [
    "df17=pd.DataFrame({})\n",
    "df17['Date']=date17[:1]\n",
    "df17['Author']=author17[:1]\n",
    "df17['Vertical']=vertical17[:1]\n",
    "df17['Healines']=headline17[:1]\n",
    "df17['Description']=description17[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ac5e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "d92e7a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "date17a=[]\n",
    "author17a=[]\n",
    "vertical17a=[]\n",
    "headline17a=[]\n",
    "description17a=[]\n",
    "\n",
    "# scrapping details 17 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date17a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author17a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical17a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline17a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description17a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "999a438b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df17a=pd.DataFrame({})\n",
    "df17a['Date']=date17a[:1]\n",
    "df17a['Author']=author17a[:1]\n",
    "df17a['Vertical']=vertical17a[:1]\n",
    "df17a['Healines']=headline17a[:1]\n",
    "df17a['Description']=description17a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e051b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "bb0830fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "date17b=[]\n",
    "author17b=[]\n",
    "vertical17b=[]\n",
    "headline17b=[]\n",
    "description17b=[]\n",
    "\n",
    "# scrapping details 17 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date17b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author17b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical17b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline17b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description17b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "57e25c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df17b=pd.DataFrame({})\n",
    "df17b['Date']=date17b[:1]\n",
    "df17b['Author']=author17b[:1]\n",
    "df17b['Vertical']=vertical17b[:1]\n",
    "df17b['Healines']=headline17b[:1]\n",
    "df17b['Description']=description17b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02394d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "3631b713",
   "metadata": {},
   "outputs": [],
   "source": [
    "date17c=[]\n",
    "author17c=[]\n",
    "vertical17c=[]\n",
    "headline17c=[]\n",
    "description17c=[]\n",
    "\n",
    "# scrapping details 17 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date17c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author17c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical17c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline17c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description17c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "ab6655ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df17c=pd.DataFrame({})\n",
    "df17c['Date']=date17c[:1]\n",
    "df17c['Author']=author17c[:1]\n",
    "df17c['Vertical']=vertical17c[:1]\n",
    "df17c['Healines']=headline17c[:1]\n",
    "df17c['Description']=description17c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d679e77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "2c1d621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "date17d=[]\n",
    "author17d=[]\n",
    "vertical17d=[]\n",
    "headline17d=[]\n",
    "description17d=[]\n",
    "\n",
    "# scrapping details 17 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date17d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author17d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical17d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline17d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description17d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "00fecf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df17d=pd.DataFrame({})\n",
    "df17d['Date']=date17d[:1]\n",
    "df17d['Author']=author17d[:1]\n",
    "df17d['Vertical']=vertical17d[:1]\n",
    "df17d['Healines']=headline17d[:1]\n",
    "df17d['Description']=description17d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a73bf0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "2fd8ad54",
   "metadata": {},
   "outputs": [],
   "source": [
    "date17e=[]\n",
    "author17e=[]\n",
    "vertical17e=[]\n",
    "headline17e=[]\n",
    "description17e=[]\n",
    "\n",
    "# scrapping details 17 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date17e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author17e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical17e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline17e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description17e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "80267edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df17e=pd.DataFrame({})\n",
    "df17e['Date']=date17e[:1]\n",
    "df17e['Author']=author17e[:1]\n",
    "df17e['Vertical']=vertical17e[:1]\n",
    "df17e['Healines']=headline17e[:1]\n",
    "df17e['Description']=description17e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42b0ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "9049bf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date17f=[]\n",
    "author17f=[]\n",
    "vertical17f=[]\n",
    "headline17f=[]\n",
    "description17f=[]\n",
    "\n",
    "# scrapping details 17 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date17f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author17f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical17f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline17f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description17f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "a8a6ea89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df17f=pd.DataFrame({})\n",
    "df17f['Date']=date17f[:1]\n",
    "df17f['Author']=author17f[:1]\n",
    "df17f['Vertical']=vertical17f[:1]\n",
    "df17f['Healines']=headline17f[:1]\n",
    "df17f['Description']=description17f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf81df80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "b512df37",
   "metadata": {},
   "outputs": [],
   "source": [
    "date17g=[]\n",
    "author17g=[]\n",
    "vertical17g=[]\n",
    "headline17g=[]\n",
    "description17g=[]\n",
    "\n",
    "# scrapping details 17 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date17g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author17g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical17g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline17g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description17g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "cccf2d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df17g=pd.DataFrame({})\n",
    "df17g['Date']=date17g[:1]\n",
    "df17g['Author']=author17g[:1]\n",
    "df17g['Vertical']=vertical17g[:1]\n",
    "df17g['Healines']=headline17g[:1]\n",
    "df17g['Description']=description17g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739fd9fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "d3af7d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "date17h=[]\n",
    "author17h=[]\n",
    "vertical17h=[]\n",
    "headline17h=[]\n",
    "description17h=[]\n",
    "\n",
    "# scrapping details 17 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date17h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author17h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical17h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline17h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description17h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "40e512fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df17h=pd.DataFrame({})\n",
    "df17h['Date']=date17h[:1]\n",
    "df17h['Author']=author17h[:1]\n",
    "df17h['Vertical']=vertical17h[:1]\n",
    "df17h['Healines']=headline17h[:1]\n",
    "df17h['Description']=description17h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77d94eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "b963d127",
   "metadata": {},
   "outputs": [],
   "source": [
    "date17i=[]\n",
    "author17i=[]\n",
    "vertical17i=[]\n",
    "headline17i=[]\n",
    "description17i=[]\n",
    "\n",
    "# scrapping details 17 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date17i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author17i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical17i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline17i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description17i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "9a6f52dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df17i=pd.DataFrame({})\n",
    "df17i['Date']=date17i[:1]\n",
    "df17i['Author']=author17i[:1]\n",
    "df17i['Vertical']=vertical17i[:1]\n",
    "df17i['Healines']=headline17i[:1]\n",
    "df17i['Description']=description17i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a1d7b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c620d522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "e0ffa54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date18=[]\n",
    "author18=[]\n",
    "vertical18=[]\n",
    "headline18=[]\n",
    "description18=[]\n",
    "\n",
    "# scrapping details 18 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date18.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author18.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical18.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline18.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description18.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "fc032887",
   "metadata": {},
   "outputs": [],
   "source": [
    "df18=pd.DataFrame({})\n",
    "df18['Date']=date18[:1]\n",
    "df18['Author']=author18[:1]\n",
    "df18['Vertical']=vertical18[:1]\n",
    "df18['Healines']=headline18[:1]\n",
    "df18['Description']=description18[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592ba186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "8a8469ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "date18a=[]\n",
    "author18a=[]\n",
    "vertical18a=[]\n",
    "headline18a=[]\n",
    "description18a=[]\n",
    "\n",
    "# scrapping details 18 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date18a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author18a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical18a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline18a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description18a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "668daed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df18a=pd.DataFrame({})\n",
    "df18a['Date']=date18a[:1]\n",
    "df18a['Author']=author18a[:1]\n",
    "df18a['Vertical']=vertical18a[:1]\n",
    "df18a['Healines']=headline18a[:1]\n",
    "df18a['Description']=description18a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2420b43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "7f3c5f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "date18b=[]\n",
    "author18b=[]\n",
    "vertical18b=[]\n",
    "headline18b=[]\n",
    "description18b=[]\n",
    "\n",
    "# scrapping details 18 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date18b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author18b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical18b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline18b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description18b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "5eb6f5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df18b=pd.DataFrame({})\n",
    "df18b['Date']=date18b[:1]\n",
    "df18b['Author']=author18b[:1]\n",
    "df18b['Vertical']=vertical18b[:1]\n",
    "df18b['Healines']=headline18b[:1]\n",
    "df18b['Description']=description18b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba46a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "de97b800",
   "metadata": {},
   "outputs": [],
   "source": [
    "date18c=[]\n",
    "author18c=[]\n",
    "vertical18c=[]\n",
    "headline18c=[]\n",
    "description18c=[]\n",
    "\n",
    "# scrapping details 18 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date18c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author18c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical18c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline18c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description18c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "38637898",
   "metadata": {},
   "outputs": [],
   "source": [
    "df18c=pd.DataFrame({})\n",
    "df18c['Date']=date18c[:1]\n",
    "df18c['Author']=author18c[:1]\n",
    "df18c['Vertical']=vertical18c[:1]\n",
    "df18c['Healines']=headline18c[:1]\n",
    "df18c['Description']=description18c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8fd5a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "ccd268b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "date18d=[]\n",
    "author18d=[]\n",
    "vertical18d=[]\n",
    "headline18d=[]\n",
    "description18d=[]\n",
    "\n",
    "# scrapping details 18 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date18d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author18d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical18d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline18d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description18d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "d4455f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df18d=pd.DataFrame({})\n",
    "df18d['Date']=date18d[:1]\n",
    "df18d['Author']=author18d[:1]\n",
    "df18d['Vertical']=vertical18d[:1]\n",
    "df18d['Healines']=headline18d[:1]\n",
    "df18d['Description']=description18d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc05de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "660c4739",
   "metadata": {},
   "outputs": [],
   "source": [
    "date18e=[]\n",
    "author18e=[]\n",
    "vertical18e=[]\n",
    "headline18e=[]\n",
    "description18e=[]\n",
    "\n",
    "# scrapping details 18 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date18e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author18e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical18e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline18e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description18e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "55d9ccdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df18e=pd.DataFrame({})\n",
    "df18e['Date']=date18e[:1]\n",
    "df18e['Author']=author18e[:1]\n",
    "df18e['Vertical']=vertical18e[:1]\n",
    "df18e['Healines']=headline18e[:1]\n",
    "df18e['Description']=description18e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8025e1c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "81376266",
   "metadata": {},
   "outputs": [],
   "source": [
    "date18f=[]\n",
    "author18f=[]\n",
    "vertical18f=[]\n",
    "headline18f=[]\n",
    "description18f=[]\n",
    "\n",
    "# scrapping details 18 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date18f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author18f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical18f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline18f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description18f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "d4cf45ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df18f=pd.DataFrame({})\n",
    "df18f['Date']=date18f[:1]\n",
    "df18f['Author']=author18f[:1]\n",
    "df18f['Vertical']=vertical18f[:1]\n",
    "df18f['Healines']=headline18f[:1]\n",
    "df18f['Description']=description18f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec4d4b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "1fe43e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date18g=[]\n",
    "author18g=[]\n",
    "vertical18g=[]\n",
    "headline18g=[]\n",
    "description18g=[]\n",
    "\n",
    "# scrapping details 18 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date18g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author18g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical18g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline18g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description18g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "50ebbc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df18g=pd.DataFrame({})\n",
    "df18g['Date']=date18g[:1]\n",
    "df18g['Author']=author18g[:1]\n",
    "df18g['Vertical']=vertical18g[:1]\n",
    "df18g['Healines']=headline18g[:1]\n",
    "df18g['Description']=description18g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd31e60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "8d9c03c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "date18h=[]\n",
    "author18h=[]\n",
    "vertical18h=[]\n",
    "headline18h=[]\n",
    "description18h=[]\n",
    "\n",
    "# scrapping details 18 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date18h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author18h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical18h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline18h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description18h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "af6c7531",
   "metadata": {},
   "outputs": [],
   "source": [
    "df18h=pd.DataFrame({})\n",
    "df18h['Date']=date18h[:1]\n",
    "df18h['Author']=author18h[:1]\n",
    "df18h['Vertical']=vertical18h[:1]\n",
    "df18h['Healines']=headline18h[:1]\n",
    "df18h['Description']=description18h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51420d94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "ce7e7453",
   "metadata": {},
   "outputs": [],
   "source": [
    "date18i=[]\n",
    "author18i=[]\n",
    "vertical18i=[]\n",
    "headline18i=[]\n",
    "description18i=[]\n",
    "\n",
    "# scrapping details 18 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date18i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author18i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical18i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "    headline18i.append(i.text)\n",
    "    \n",
    "     \n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description18i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "e972c323",
   "metadata": {},
   "outputs": [],
   "source": [
    "df18i=pd.DataFrame({})\n",
    "df18i['Date']=date18i[:1]\n",
    "df18i['Author']=author18i[:1]\n",
    "df18i['Vertical']=vertical18i[:1]\n",
    "df18i['Healines']=headline18i[:1]\n",
    "df18i['Description']=description18i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13bef63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f955a03d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "1c5f1fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "date19=[]\n",
    "author19=[]\n",
    "vertical19=[]\n",
    "headline19=[]\n",
    "description19=[]\n",
    "\n",
    "# scrapping details 19 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date19.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author19.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical19.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline19.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description19.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "6943ea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df19=pd.DataFrame({})\n",
    "df19['Date']=date19[:1]\n",
    "df19['Author']=author19[:1]\n",
    "df19['Vertical']=vertical19[:1]\n",
    "df19['Healines']=headline19[:1]\n",
    "df19['Description']=description19[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6027ecf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "39d61b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "date19a=[]\n",
    "author19a=[]\n",
    "vertical19a=[]\n",
    "headline19a=[]\n",
    "description19a=[]\n",
    "\n",
    "# scrapping details 19 may 2021\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date19a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author19a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical19a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline19a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description19a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "de6c0cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df19a=pd.DataFrame({})\n",
    "df19a['Date']=date19a[:1]\n",
    "df19a['Author']=author19a[:1]\n",
    "df19a['Vertical']=vertical19a[:1]\n",
    "df19a['Healines']=headline19a[:1]\n",
    "df19a['Description']=description19a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5df0d97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "7de8bc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date19b=[]\n",
    "author19b=[]\n",
    "vertical19b=[]\n",
    "headline19b=[]\n",
    "description19b=[]\n",
    "\n",
    "# scrapping details 19 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date19b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author19b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical19b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline19b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description19b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "1c5d8e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df19b=pd.DataFrame({})\n",
    "df19b['Date']=date19b[:1]\n",
    "df19b['Author']=author19b[:1]\n",
    "df19b['Vertical']=vertical19b[:1]\n",
    "df19b['Healines']=headline19b[:1]\n",
    "df19b['Description']=description19b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474f82f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "cbe2fb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "date19c=[]\n",
    "author19c=[]\n",
    "vertical19c=[]\n",
    "headline19c=[]\n",
    "description19c=[]\n",
    "\n",
    "# scrapping details 19 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date19c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author19c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical19c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline19c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description19c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "3477ee92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df19c=pd.DataFrame({})\n",
    "df19c['Date']=date19c[:1]\n",
    "df19c['Author']=author19c[:1]\n",
    "df19c['Vertical']=vertical19c[:1]\n",
    "df19c['Healines']=headline19c[:1]\n",
    "df19c['Description']=description19c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bed3f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "ad2f744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date19d=[]\n",
    "author19d=[]\n",
    "vertical19d=[]\n",
    "headline19d=[]\n",
    "description19d=[]\n",
    "\n",
    "# scrapping details 19 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date19d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author19d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical19d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline19d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description19d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "fa6c27f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df19d=pd.DataFrame({})\n",
    "df19d['Date']=date19d[:1]\n",
    "df19d['Author']=author19d[:1]\n",
    "df19d['Vertical']=vertical19d[:1]\n",
    "df19d['Healines']=headline19d[:1]\n",
    "df19d['Description']=description19d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9a7a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "4d06d701",
   "metadata": {},
   "outputs": [],
   "source": [
    "date19e=[]\n",
    "author19e=[]\n",
    "vertical19e=[]\n",
    "headline19e=[]\n",
    "description19e=[]\n",
    "\n",
    "# scrapping details 19 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date19e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author19e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical19e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline19e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description19e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "5b7a0f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df19e=pd.DataFrame({})\n",
    "df19e['Date']=date19e[:1]\n",
    "df19e['Author']=author19e[:1]\n",
    "df19e['Vertical']=vertical19e[:1]\n",
    "df19e['Healines']=headline19e[:1]\n",
    "df19e['Description']=description19e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9f3359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "fd4a952e",
   "metadata": {},
   "outputs": [],
   "source": [
    "date19f=[]\n",
    "author19f=[]\n",
    "vertical19f=[]\n",
    "headline19f=[]\n",
    "description19f=[]\n",
    "\n",
    "# scrapping details 19 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date19f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author19f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical19f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline19f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description19f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "0cfa7aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df19f=pd.DataFrame({})\n",
    "df19f['Date']=date19f[:1]\n",
    "df19f['Author']=author19f[:1]\n",
    "df19f['Vertical']=vertical19f[:1]\n",
    "df19f['Healines']=headline19f[:1]\n",
    "df19f['Description']=description19f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ccd58e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "61060883",
   "metadata": {},
   "outputs": [],
   "source": [
    "date19g=[]\n",
    "author19g=[]\n",
    "vertical19g=[]\n",
    "headline19g=[]\n",
    "description19g=[]\n",
    "\n",
    "# scrapping details 19 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date19g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author19g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical19g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline19g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description19g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "b9603227",
   "metadata": {},
   "outputs": [],
   "source": [
    "df19g=pd.DataFrame({})\n",
    "df19g['Date']=date19g[:1]\n",
    "df19g['Author']=author19g[:1]\n",
    "df19g['Vertical']=vertical19g[:1]\n",
    "df19g['Healines']=headline19g[:1]\n",
    "df19g['Description']=description19g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f976776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "f5af40fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "date19h=[]\n",
    "author19h=[]\n",
    "vertical19h=[]\n",
    "headline19h=[]\n",
    "description19h=[]\n",
    "\n",
    "# scrapping details 19 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date19h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author19h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical19h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline19h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description19h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "0c3ed6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df19h=pd.DataFrame({})\n",
    "df19h['Date']=date19h[:1]\n",
    "df19h['Author']=author19h[:1]\n",
    "df19h['Vertical']=vertical19h[:1]\n",
    "df19h['Healines']=headline19h[:1]\n",
    "df19h['Description']=description19h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccebeaba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "2ec7ecd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "date19i=[]\n",
    "author19i=[]\n",
    "vertical19i=[]\n",
    "headline19i=[]\n",
    "description19i=[]\n",
    "\n",
    "# scrapping details 19 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date19i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author19i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical19i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline19i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description19i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "eef2f20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df19i=pd.DataFrame({})\n",
    "df19i['Date']=date19i[:1]\n",
    "df19i['Author']=author19i[:1]\n",
    "df19i['Vertical']=vertical19i[:1]\n",
    "df19i['Healines']=headline19i[:1]\n",
    "df19i['Description']=description19i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c44402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "ddc4d3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "date20=[]\n",
    "author20=[]\n",
    "vertical20=[]\n",
    "headline20=[]\n",
    "description20=[]\n",
    "\n",
    "# scrapping details 20 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date20.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author20.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical20.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline20.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description20.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "c8e1ed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df20=pd.DataFrame({})\n",
    "df20['Date']=date20[:1]\n",
    "df20['Author']=author20[:1]\n",
    "df20['Vertical']=vertical20[:1]\n",
    "df20['Healines']=headline20[:1]\n",
    "df20['Description']=description20[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee4daac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595bb5c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "e654def8",
   "metadata": {},
   "outputs": [],
   "source": [
    "date20a=[]\n",
    "author20a=[]\n",
    "vertical20a=[]\n",
    "headline20a=[]\n",
    "description20a=[]\n",
    "\n",
    "# scrapping details 20 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date20a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author20a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical20a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline20a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description20a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "bd906c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df20a=pd.DataFrame({})\n",
    "df20a['Date']=date20a[:1]\n",
    "df20a['Author']=author20a[:1]\n",
    "df20a['Vertical']=vertical20a[:1]\n",
    "df20a['Healines']=headline20a[:1]\n",
    "df20a['Description']=description20a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49455ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "2747701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "date20b=[]\n",
    "author20b=[]\n",
    "vertical20b=[]\n",
    "headline20b=[]\n",
    "description20b=[]\n",
    "\n",
    "# scrapping details 20 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date20b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author20b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical20b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline20b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description20b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "b91b0136",
   "metadata": {},
   "outputs": [],
   "source": [
    "df20b=pd.DataFrame({})\n",
    "df20b['Date']=date20b[:1]\n",
    "df20b['Author']=author20b[:1]\n",
    "df20b['Vertical']=vertical20b[:1]\n",
    "df20b['Healines']=headline20b[:1]\n",
    "df20b['Description']=description20b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279b5fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "43d9710a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date20c=[]\n",
    "author20c=[]\n",
    "vertical20c=[]\n",
    "headline20c=[]\n",
    "description20c=[]\n",
    "\n",
    "# scrapping details 20 amy 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date20c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author20c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical20c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline20c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description20c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "b2b5a1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df20c=pd.DataFrame({})\n",
    "df20c['Date']=date20c[:1]\n",
    "df20c['Author']=author20c[:1]\n",
    "df20c['Vertical']=vertical20c[:1]\n",
    "df20c['Healines']=headline20c[:1]\n",
    "df20c['Description']=description20c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c6f5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "6db72cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "date20d=[]\n",
    "author20d=[]\n",
    "vertical20d=[]\n",
    "headline20d=[]\n",
    "description20d=[]\n",
    "\n",
    "# scrapping details 20 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date20d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author20d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical20d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline20d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description20d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "d2f05bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df20d=pd.DataFrame({})\n",
    "df20d['Date']=date20d[:1]\n",
    "df20d['Author']=author20d[:1]\n",
    "df20d['Vertical']=vertical20d[:1]\n",
    "df20d['Healines']=headline20d[:1]\n",
    "df20d['Description']=description20d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc7d95b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "211495d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "date20e=[]\n",
    "author20e=[]\n",
    "vertical20e=[]\n",
    "headline20e=[]\n",
    "description20e=[]\n",
    "\n",
    "# scrapping details 20 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date20e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author20e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical20e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline20e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description20e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "97bda779",
   "metadata": {},
   "outputs": [],
   "source": [
    "df20e=pd.DataFrame({})\n",
    "df20e['Date']=date20e[:1]\n",
    "df20e['Author']=author20e[:1]\n",
    "df20e['Vertical']=vertical20e[:1]\n",
    "df20e['Healines']=headline20e[:1]\n",
    "df20e['Description']=description20e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560141ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "ae5c40c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "date20f=[]\n",
    "author20f=[]\n",
    "vertical20f=[]\n",
    "headline20f=[]\n",
    "description20f=[]\n",
    "\n",
    "# scrapping details 20 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date20f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author20f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical20f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline20f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description20f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "3f925884",
   "metadata": {},
   "outputs": [],
   "source": [
    "df20f=pd.DataFrame({})\n",
    "df20f['Date']=date20f[:1]\n",
    "df20f['Author']=author20f[:1]\n",
    "df20f['Vertical']=vertical20f[:1]\n",
    "df20f['Healines']=headline20f[:1]\n",
    "df20f['Description']=description20f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f5fe9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "286ea37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "date20g=[]\n",
    "author20g=[]\n",
    "vertical20g=[]\n",
    "headline20g=[]\n",
    "description20g=[]\n",
    "\n",
    "# scrapping details 20 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date20g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author20g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical20g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline20g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description20g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "ec9d1412",
   "metadata": {},
   "outputs": [],
   "source": [
    "df20g=pd.DataFrame({})\n",
    "df20g['Date']=date20g[:1]\n",
    "df20g['Author']=author20g[:1]\n",
    "df20g['Vertical']=vertical20g[:1]\n",
    "df20g['Healines']=headline20g[:1]\n",
    "df20g['Description']=description20g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a998b3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "801cafe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "date20h=[]\n",
    "author20h=[]\n",
    "vertical20h=[]\n",
    "headline20h=[]\n",
    "description20h=[]\n",
    "\n",
    "# scrapping details 20 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date20h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author20h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical20h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline20h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description20h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "0d699f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df20h=pd.DataFrame({})\n",
    "df20h['Date']=date20h[:1]\n",
    "df20h['Author']=author20h[:1]\n",
    "df20h['Vertical']=vertical20h[:1]\n",
    "df20h['Healines']=headline20h[:1]\n",
    "df20h['Description']=description20h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e56a34e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "d9c024ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "date20i=[]\n",
    "author20i=[]\n",
    "vertical20i=[]\n",
    "headline20i=[]\n",
    "description20i=[]\n",
    "\n",
    "# scrapping details 20 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date20i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author20i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical20i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline20i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description20i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "2e8b0499",
   "metadata": {},
   "outputs": [],
   "source": [
    "df20i=pd.DataFrame({})\n",
    "df20i['Date']=date20i[:1]\n",
    "df20i['Author']=author20i[:1]\n",
    "df20i['Vertical']=vertical20i[:1]\n",
    "df20i['Healines']=headline20i[:1]\n",
    "df20i['Description']=description20i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adbbb44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca71e139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "81281e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date21=[]\n",
    "author21=[]\n",
    "vertical21=[]\n",
    "headline21=[]\n",
    "description21=[]\n",
    "\n",
    "# scrapping details 21 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date21.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author21.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical21.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline21.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description21.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "0971591b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df21=pd.DataFrame({})\n",
    "df21['Date']=date21[:1]\n",
    "df21['Author']=author21[:1]\n",
    "df21['Vertical']=vertical21[:1]\n",
    "df21['Healines']=headline21[:1]\n",
    "df21['Description']=description21[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6653d562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "dbfe62c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "date21a=[]\n",
    "author21a=[]\n",
    "vertical21a=[]\n",
    "headline21a=[]\n",
    "description21a=[]\n",
    "\n",
    "# scrapping details 21 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date21a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author21a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical21a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline21a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description21a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "4fcfd487",
   "metadata": {},
   "outputs": [],
   "source": [
    "df21a=pd.DataFrame({})\n",
    "df21a['Date']=date21a[:1]\n",
    "df21a['Author']=author21a[:1]\n",
    "df21a['Vertical']=vertical21a[:1]\n",
    "df21a['Healines']=headline21a[:1]\n",
    "df21a['Description']=description21a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56bf1fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "4d31ef51",
   "metadata": {},
   "outputs": [],
   "source": [
    "date21b=[]\n",
    "author21b=[]\n",
    "vertical21b=[]\n",
    "headline21b=[]\n",
    "description21b=[]\n",
    "\n",
    "# scrapping details 21 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date21b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author21b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical21b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline21b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description21b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "a9e4d94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df21b=pd.DataFrame({})\n",
    "df21b['Date']=date21b[:1]\n",
    "df21b['Author']=author21b[:1]\n",
    "df21b['Vertical']=vertical21b[:1]\n",
    "df21b['Healines']=headline21b[:1]\n",
    "df21b['Description']=description21b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a39a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "83b6c17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "date21c=[]\n",
    "author21c=[]\n",
    "vertical21c=[]\n",
    "headline21c=[]\n",
    "description21c=[]\n",
    "\n",
    "# scrapping details 21 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date21c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author21c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical21c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline21c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description21c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "4b96b35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df21c=pd.DataFrame({})\n",
    "df21c['Date']=date21c[:1]\n",
    "df21c['Author']=author21c[:1]\n",
    "df21c['Vertical']=vertical21c[:1]\n",
    "df21c['Healines']=headline21c[:1]\n",
    "df21c['Description']=description21c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997b6476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "11b908a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "date21d=[]\n",
    "author21d=[]\n",
    "vertical21d=[]\n",
    "headline21d=[]\n",
    "description21d=[]\n",
    "\n",
    "# scrapping details 21 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date21d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author21d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical21d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline21d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description21d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "e3a2239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df21d=pd.DataFrame({})\n",
    "df21d['Date']=date21d[:1]\n",
    "df21d['Author']=author21d[:1]\n",
    "df21d['Vertical']=vertical21d[:1]\n",
    "df21d['Healines']=headline21d[:1]\n",
    "df21d['Description']=description21d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6911662d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "f9f7e0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "date21e=[]\n",
    "author21e=[]\n",
    "vertical21e=[]\n",
    "headline21e=[]\n",
    "description21e=[]\n",
    "\n",
    "# scrapping details 21 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date21e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author21e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical21e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline21e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description21e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "c3becf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df21e=pd.DataFrame({})\n",
    "df21e['Date']=date21e[:1]\n",
    "df21e['Author']=author21e[:1]\n",
    "df21e['Vertical']=vertical21e[:1]\n",
    "df21e['Healines']=headline21e[:1]\n",
    "df21e['Description']=description21e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a70ca13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "ffb77942",
   "metadata": {},
   "outputs": [],
   "source": [
    "date21f=[]\n",
    "author21f=[]\n",
    "vertical21f=[]\n",
    "headline21f=[]\n",
    "description21f=[]\n",
    "\n",
    "# scrapping details 21 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date21f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author21f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical21f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline21f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description21f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "87874ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df21f=pd.DataFrame({})\n",
    "df21f['Date']=date21f[:1]\n",
    "df21f['Author']=author21f[:1]\n",
    "df21f['Vertical']=vertical21f[:1]\n",
    "df21f['Healines']=headline21f[:1]\n",
    "df21f['Description']=description21f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216fa23d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "32c04715",
   "metadata": {},
   "outputs": [],
   "source": [
    "date21g=[]\n",
    "author21g=[]\n",
    "vertical21g=[]\n",
    "headline21g=[]\n",
    "description21g=[]\n",
    "\n",
    "# scrapping details 21 amy 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date21g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author21g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical21g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline21g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description21g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "0923dee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df21g=pd.DataFrame({})\n",
    "df21g['Date']=date21g[:1]\n",
    "df21g['Author']=author21g[:1]\n",
    "df21g['Vertical']=vertical21g[:1]\n",
    "df21g['Healines']=headline21g[:1]\n",
    "df21g['Description']=description21g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3f5133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "64650f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "date21h=[]\n",
    "author21h=[]\n",
    "vertical21h=[]\n",
    "headline21h=[]\n",
    "description21h=[]\n",
    "\n",
    "# scrapping details 21 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date21h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author21h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical21h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline21h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description21h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "8cfa7a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df21h=pd.DataFrame({})\n",
    "df21h['Date']=date21h[:1]\n",
    "df21h['Author']=author21h[:1]\n",
    "df21h['Vertical']=vertical21h[:1]\n",
    "df21h['Healines']=headline21h[:1]\n",
    "df21h['Description']=description21h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd22ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "3395840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "date21i=[]\n",
    "author21i=[]\n",
    "vertical21i=[]\n",
    "headline21i=[]\n",
    "description21i=[]\n",
    "\n",
    "# scrapping details 21 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date21i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author21i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical21i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline21i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description21i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "4bab2295",
   "metadata": {},
   "outputs": [],
   "source": [
    "df21i=pd.DataFrame({})\n",
    "df21i['Date']=date21i[:1]\n",
    "df21i['Author']=author21i[:1]\n",
    "df21i['Vertical']=vertical21i[:1]\n",
    "df21i['Healines']=headline21i[:1]\n",
    "df21i['Description']=description21i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300f5e74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc630ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "f41d22b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "date22=[]\n",
    "author22=[]\n",
    "vertical22=[]\n",
    "headline22=[]\n",
    "description22=[]\n",
    "\n",
    "# scrapping details 22 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date22.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author22.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical22.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline22.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description22.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "34351d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df22=pd.DataFrame({})\n",
    "df22['Date']=date22[:1]\n",
    "df22['Author']=author22[:1]\n",
    "df22['Vertical']=vertical22[:1]\n",
    "df22['Healines']=headline22[:1]\n",
    "df22['Description']=description22[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b621887d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "82c1afbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "date22a=[]\n",
    "author22a=[]\n",
    "vertical22a=[]\n",
    "headline22a=[]\n",
    "description22a=[]\n",
    "\n",
    "# scrapping details 22 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date22a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author22a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical22a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline22a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description22a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "476bff03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df22a=pd.DataFrame({})\n",
    "df22a['Date']=date22a[:1]\n",
    "df22a['Author']=author22a[:1]\n",
    "df22a['Vertical']=vertical22a[:1]\n",
    "df22a['Healines']=headline22a[:1]\n",
    "df22a['Description']=description22a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e47e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "62b51c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "date22b=[]\n",
    "author22b=[]\n",
    "vertical22b=[]\n",
    "headline22b=[]\n",
    "description22b=[]\n",
    "\n",
    "# scrapping details 22 amy 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date22b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author22b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical22b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline22b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description22b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "86d7df72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df22b=pd.DataFrame({})\n",
    "df22b['Date']=date22b[:1]\n",
    "df22b['Author']=author22b[:1]\n",
    "df22b['Vertical']=vertical22b[:1]\n",
    "df22b['Healines']=headline22b[:1]\n",
    "df22b['Description']=description22b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccc3038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "9ea41b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "date22c=[]\n",
    "author22c=[]\n",
    "vertical22c=[]\n",
    "headline22c=[]\n",
    "description22c=[]\n",
    "\n",
    "# scrapping details 22 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date22c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author22c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical22c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline22c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description22c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "10ee3046",
   "metadata": {},
   "outputs": [],
   "source": [
    "df22c=pd.DataFrame({})\n",
    "df22c['Date']=date22c[:1]\n",
    "df22['Author']=author22c[:1]\n",
    "df22c['Vertical']=vertical22c[:1]\n",
    "df22c['Healines']=headline22c[:1]\n",
    "df22c['Description']=description22c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f640e948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "c2ead032",
   "metadata": {},
   "outputs": [],
   "source": [
    "date22d=[]\n",
    "author22d=[]\n",
    "vertical22d=[]\n",
    "headline22d=[]\n",
    "description22d=[]\n",
    "\n",
    "# scrapping details 22 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date22d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author22d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical22d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline22d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description22d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "3a135387",
   "metadata": {},
   "outputs": [],
   "source": [
    "df22d=pd.DataFrame({})\n",
    "df22d['Date']=date22d[:1]\n",
    "df22d['Author']=author22d[:1]\n",
    "df22d['Vertical']=vertical22d[:1]\n",
    "df22d['Healines']=headline22d[:1]\n",
    "df22d['Description']=description22d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a82f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "065686f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "date22e=[]\n",
    "author22e=[]\n",
    "vertical22e=[]\n",
    "headline22e=[]\n",
    "description22e=[]\n",
    "\n",
    "# scrapping details 22 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date22e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author22e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical22e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline22e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description22e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "f45e05f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df22e=pd.DataFrame({})\n",
    "df22e['Date']=date22e[:1]\n",
    "df22e['Author']=author22e[:1]\n",
    "df22e['Vertical']=vertical22e[:1]\n",
    "df22e['Healines']=headline22e[:1]\n",
    "df22e['Description']=description22e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51de9c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "a3ef1874",
   "metadata": {},
   "outputs": [],
   "source": [
    "date22f=[]\n",
    "author22f=[]\n",
    "vertical22f=[]\n",
    "headline22f=[]\n",
    "description22f=[]\n",
    "\n",
    "# scrapping details 22 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date22f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author22f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical22f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline22f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description22f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "a997c61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df22f=pd.DataFrame({})\n",
    "df22f['Date']=date22f[:1]\n",
    "df22f['Author']=author22f[:1]\n",
    "df22f['Vertical']=vertical22f[:1]\n",
    "df22f['Healines']=headline22f[:1]\n",
    "df22f['Description']=description22f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bec1d58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "84322faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "date22g=[]\n",
    "author22g=[]\n",
    "vertical22g=[]\n",
    "headline22g=[]\n",
    "description22g=[]\n",
    "\n",
    "# scrapping details 22 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date22g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author22g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical22g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline22g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description22g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "8edd5b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df22g=pd.DataFrame({})\n",
    "df22g['Date']=date22g[:1]\n",
    "df22g['Author']=author22g[:1]\n",
    "df22g['Vertical']=vertical22g[:1]\n",
    "df22g['Healines']=headline22g[:1]\n",
    "df22g['Description']=description22g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d317f227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "8803004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date22h=[]\n",
    "author22h=[]\n",
    "vertical22h=[]\n",
    "headline22h=[]\n",
    "description22h=[]\n",
    "\n",
    "# scrapping details 22 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date22h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author22h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical22h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline22h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description22h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "f55b563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df22h=pd.DataFrame({})\n",
    "df22h['Date']=date22h[:1]\n",
    "df22h['Author']=author22h[:1]\n",
    "df22h['Vertical']=vertical22h[:1]\n",
    "df22h['Healines']=headline22h[:1]\n",
    "df22h['Description']=description22h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9bf147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "dbeafc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "date22i=[]\n",
    "author22i=[]\n",
    "vertical22i=[]\n",
    "headline22i=[]\n",
    "description22i=[]\n",
    "\n",
    "# scrapping details 22 amy 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date22i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author22i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical22i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline22i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description22i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "82088587",
   "metadata": {},
   "outputs": [],
   "source": [
    "df22i=pd.DataFrame({})\n",
    "df22i['Date']=date22i[:1]\n",
    "df22i['Author']=author22i[:1]\n",
    "df22i['Vertical']=vertical22i[:1]\n",
    "df22i['Healines']=headline22i[:1]\n",
    "df22i['Description']=description22i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952d8266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f66d63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "cdd6f08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "date23=[]\n",
    "author23=[]\n",
    "vertical23=[]\n",
    "headline23=[]\n",
    "description23=[]\n",
    "\n",
    "# scrapping details 23 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date23.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author23.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical23.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline23.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description23.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "0ffe3cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df23=pd.DataFrame({})\n",
    "df23['Date']=date23[:1]\n",
    "df23['Author']=author23[:1]\n",
    "df23['Vertical']=vertical23[:1]\n",
    "df23['Healines']=headline23[:1]\n",
    "df23['Description']=description23[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fe1c93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "cf774513",
   "metadata": {},
   "outputs": [],
   "source": [
    "date23a=[]\n",
    "author23a=[]\n",
    "vertical23a=[]\n",
    "headline23a=[]\n",
    "description23a=[]\n",
    "\n",
    "# scrapping details 23 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date23a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author23a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical23a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline23a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description23a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "edd1ab22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df23a=pd.DataFrame({})\n",
    "df23a['Date']=date23a[:1]\n",
    "df23a['Author']=author23a[:1]\n",
    "df23a['Vertical']=vertical23a[:1]\n",
    "df23a['Healines']=headline23a[:1]\n",
    "df23a['Description']=description23a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac51b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "3eba3217",
   "metadata": {},
   "outputs": [],
   "source": [
    "date23b=[]\n",
    "author23b=[]\n",
    "vertical23b=[]\n",
    "headline23b=[]\n",
    "description23b=[]\n",
    "\n",
    "# scrapping details 23 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date23b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author23b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical23b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline23b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description23b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "01830910",
   "metadata": {},
   "outputs": [],
   "source": [
    "df23b=pd.DataFrame({})\n",
    "df23b['Date']=date23b[:1]\n",
    "df23b['Author']=author23b[:1]\n",
    "df23b['Vertical']=vertical23b[:1]\n",
    "df23b['Healines']=headline23b[:1]\n",
    "df23b['Description']=description23b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad03c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "ab3ba80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "date23c=[]\n",
    "author23c=[]\n",
    "vertical23c=[]\n",
    "headline23c=[]\n",
    "description23c=[]\n",
    "\n",
    "# scrapping details 23 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date23c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author23c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical23c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline23c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description23c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "85c62f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df23c=pd.DataFrame({})\n",
    "df23c['Date']=date23c[:1]\n",
    "df23c['Author']=author23c[:1]\n",
    "df23c['Vertical']=vertical23c[:1]\n",
    "df23c['Healines']=headline23c[:1]\n",
    "df23c['Description']=description23c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ededbf7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "7c3f78e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "date23d=[]\n",
    "author23d=[]\n",
    "vertical23d=[]\n",
    "headline23d=[]\n",
    "description23d=[]\n",
    "\n",
    "# scrapping details 23 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date23d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author23d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical23d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline23d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description23d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "f66ffd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df23d=pd.DataFrame({})\n",
    "df23d['Date']=date23d[:1]\n",
    "df23d['Author']=author23d[:1]\n",
    "df23d['Vertical']=vertical23d[:1]\n",
    "df23d['Healines']=headline23d[:1]\n",
    "df23d['Description']=description23d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b1cd88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "97c99c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date23e=[]\n",
    "author23e=[]\n",
    "vertical23e=[]\n",
    "headline23e=[]\n",
    "description23e=[]\n",
    "\n",
    "# scrapping details 23 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date23e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author23e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical23e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline23e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description23e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "ad8bf079",
   "metadata": {},
   "outputs": [],
   "source": [
    "df23e=pd.DataFrame({})\n",
    "df23e['Date']=date23e[:1]\n",
    "df23e['Author']=author23e[:1]\n",
    "df23e['Vertical']=vertical23e[:1]\n",
    "df23e['Healines']=headline23e[:1]\n",
    "df23e['Description']=description23e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5950012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "24f0e45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "date23f=[]\n",
    "author23f=[]\n",
    "vertical23f=[]\n",
    "headline23f=[]\n",
    "description23f=[]\n",
    "\n",
    "# scrapping details 23 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date23f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author23f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical23f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline23f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description23f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "02650a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df23f=pd.DataFrame({})\n",
    "df23f['Date']=date23f[:1]\n",
    "df23f['Author']=author23f[:1]\n",
    "df23f['Vertical']=vertical23f[:1]\n",
    "df23f['Healines']=headline23f[:1]\n",
    "df23f['Description']=description23f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c971bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "b7d1bd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "date23g=[]\n",
    "author23g=[]\n",
    "vertical23g=[]\n",
    "headline23g=[]\n",
    "description23g=[]\n",
    "\n",
    "# scrapping details 23 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date23g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author23g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical23g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline23g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description23g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "74f46c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df23g=pd.DataFrame({})\n",
    "df23g['Date']=date23g[:1]\n",
    "df23g['Author']=author23g[:1]\n",
    "df23g['Vertical']=vertical23g[:1]\n",
    "df23g['Healines']=headline23g[:1]\n",
    "df23g['Description']=description23g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548e2be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "cd998e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "date23h=[]\n",
    "author23h=[]\n",
    "vertical23h=[]\n",
    "headline23h=[]\n",
    "description23h=[]\n",
    "\n",
    "# scrapping details 23 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date23h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author23h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical23h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline23h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description23h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "d6157b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df23h=pd.DataFrame({})\n",
    "df23h['Date']=date23h[:1]\n",
    "df23h['Author']=author23h[:1]\n",
    "df23h['Vertical']=vertical23h[:1]\n",
    "df23h['Healines']=headline23h[:1]\n",
    "df23h['Description']=description23h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fc1fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "2c73d728",
   "metadata": {},
   "outputs": [],
   "source": [
    "date23i=[]\n",
    "author23i=[]\n",
    "vertical23i=[]\n",
    "headline23i=[]\n",
    "description23i=[]\n",
    "\n",
    "# scrapping details 23 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date23i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author23i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical23i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline23i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description23i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "f772d73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df23i=pd.DataFrame({})\n",
    "df23i['Date']=date23i[:1]\n",
    "df23i['Author']=author23i[:1]\n",
    "df23i['Vertical']=vertical23i[:1]\n",
    "df23i['Healines']=headline23i[:1]\n",
    "df23i['Description']=description23i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1029cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcecd43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "c9e65121",
   "metadata": {},
   "outputs": [],
   "source": [
    "date24=[]\n",
    "author24=[]\n",
    "vertical24=[]\n",
    "headline24=[]\n",
    "description24=[]\n",
    "\n",
    "# scrapping details 24 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date24.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author24.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical24.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline24.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description24.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "ff5ec188",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24=pd.DataFrame({})\n",
    "df24['Date']=date24[:1]\n",
    "df24['Author']=author24[:1]\n",
    "df24['Vertical']=vertical24[:1]\n",
    "df24['Healines']=headline24[:1]\n",
    "df24['Description']=description24[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46f9812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "4e626c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "date24a=[]\n",
    "author24a=[]\n",
    "vertical24a=[]\n",
    "headline24a=[]\n",
    "description24a=[]\n",
    "\n",
    "# scrapping details 24 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date24a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author24a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical24a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline24a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description24a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "7147daa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24a=pd.DataFrame({})\n",
    "df24a['Date']=date24a[:1]\n",
    "df24a['Author']=author24a[:1]\n",
    "df24a['Vertical']=vertical24a[:1]\n",
    "df24a['Healines']=headline24a[:1]\n",
    "df24a['Description']=description24a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f481fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "20d03da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "date24b=[]\n",
    "author24b=[]\n",
    "vertical24b=[]\n",
    "headline24b=[]\n",
    "description24b=[]\n",
    "\n",
    "# scrapping details 24 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date24b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author24b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical24b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline24b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description24b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "d6d347a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24b=pd.DataFrame({})\n",
    "df24b['Date']=date24b[:1]\n",
    "df24b['Author']=author24b[:1]\n",
    "df24b['Vertical']=vertical24b[:1]\n",
    "df24b['Healines']=headline24b[:1]\n",
    "df24b['Description']=description24b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8040a36b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "560ae5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "date24c=[]\n",
    "author24c=[]\n",
    "vertical24c=[]\n",
    "headline24c=[]\n",
    "description24c=[]\n",
    "\n",
    "# scrapping details 24 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date24c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author24c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical24c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline24c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description24c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "b81c3771",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24c=pd.DataFrame({})\n",
    "df24c['Date']=date24c[:1]\n",
    "df24c['Author']=author24c[:1]\n",
    "df24c['Vertical']=vertical24c[:1]\n",
    "df24c['Healines']=headline24c[:1]\n",
    "df24c['Description']=description24c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b7a164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "472b9ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "date24d=[]\n",
    "author24d=[]\n",
    "vertical24d=[]\n",
    "headline24d=[]\n",
    "description24d=[]\n",
    "\n",
    "# scrapping details 24 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date24d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author24d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical24d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline24d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description24d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "b2f3465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24d=pd.DataFrame({})\n",
    "df24d['Date']=date24d[:1]\n",
    "df24d['Author']=author24d[:1]\n",
    "df24d['Vertical']=vertical24d[:1]\n",
    "df24d['Healines']=headline24d[:1]\n",
    "df24d['Description']=description24d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f48cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "3ba09b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "date24e=[]\n",
    "author24e=[]\n",
    "vertical24e=[]\n",
    "headline24e=[]\n",
    "description24e=[]\n",
    "\n",
    "# scrapping details 24 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date24e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author24e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical24e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline24e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description24e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "fc24cd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24e=pd.DataFrame({})\n",
    "df24e['Date']=date24e[:1]\n",
    "df24e['Author']=author24e[:1]\n",
    "df24e['Vertical']=vertical24e[:1]\n",
    "df24e['Healines']=headline24e[:1]\n",
    "df24e['Description']=description24e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6df2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "f5975546",
   "metadata": {},
   "outputs": [],
   "source": [
    "date24f=[]\n",
    "author24f=[]\n",
    "vertical24f=[]\n",
    "headline24f=[]\n",
    "description24f=[]\n",
    "\n",
    "# scrapping details 24 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date24f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author24f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical24f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline24f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description24f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "5f98a554",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24f=pd.DataFrame({})\n",
    "df24f['Date']=date24f[:1]\n",
    "df24f['Author']=author24f[:1]\n",
    "df24f['Vertical']=vertical24f[:1]\n",
    "df24f['Healines']=headline24f[:1]\n",
    "df24f['Description']=description24f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d4598c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "cb4f8912",
   "metadata": {},
   "outputs": [],
   "source": [
    "date24g=[]\n",
    "author24g=[]\n",
    "vertical24g=[]\n",
    "headline24g=[]\n",
    "description24g=[]\n",
    "\n",
    "# scrapping details 24 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date24g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author24g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical24g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline24g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description24g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "aa9399b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24g=pd.DataFrame({})\n",
    "df24g['Date']=date24g[:1]\n",
    "df24g['Author']=author24g[:1]\n",
    "df24g['Vertical']=vertical24g[:1]\n",
    "df24g['Healines']=headline24g[:1]\n",
    "df24g['Description']=description24g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44474cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "611b5c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "date24h=[]\n",
    "author24h=[]\n",
    "vertical24h=[]\n",
    "headline24h=[]\n",
    "description24h=[]\n",
    "\n",
    "# scrapping details 24 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date24h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author24h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical24h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline24h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description24h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "636866d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24h=pd.DataFrame({})\n",
    "df24h['Date']=date24h[:1]\n",
    "df24h['Author']=author24h[:1]\n",
    "df24h['Vertical']=vertical24h[:1]\n",
    "df24h['Healines']=headline24h[:1]\n",
    "df24h['Description']=description24h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d671a4d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "27595cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "date24i=[]\n",
    "author24i=[]\n",
    "vertical24i=[]\n",
    "headline24i=[]\n",
    "description24i=[]\n",
    "\n",
    "# scrapping details 24 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date24i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author24i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical24i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline24i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description24i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "56f67e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24i=pd.DataFrame({})\n",
    "df24i['Date']=date24i[:1]\n",
    "df24i['Author']=author24i[:1]\n",
    "df24i['Vertical']=vertical24i[:1]\n",
    "df24i['Healines']=headline24i[:1]\n",
    "df24i['Description']=description24i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c7012b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8b05cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "84691316",
   "metadata": {},
   "outputs": [],
   "source": [
    "date25=[]\n",
    "author25=[]\n",
    "vertical25=[]\n",
    "headline25=[]\n",
    "description25=[]\n",
    "\n",
    "# scrapping details 25 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date25.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author25.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical25.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline25.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description25.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "d896ad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df25=pd.DataFrame({})\n",
    "df25['Date']=date25[:1]\n",
    "df25['Author']=author25[:1]\n",
    "df25['Vertical']=vertical25[:1]\n",
    "df25['Healines']=headline25[:1]\n",
    "df25['Description']=description25[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0bc4be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "3f0dfbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "date25a=[]\n",
    "author25a=[]\n",
    "vertical25a=[]\n",
    "headline25a=[]\n",
    "description25a=[]\n",
    "\n",
    "# scrapping details 25 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date25a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author25a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical25a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline25a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description25a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "92d2577e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df25a=pd.DataFrame({})\n",
    "df25a['Date']=date25a[:1]\n",
    "df25a['Author']=author25a[:1]\n",
    "df25a['Vertical']=vertical25a[:1]\n",
    "df25a['Healines']=headline25a[:1]\n",
    "df25a['Description']=description25a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8401c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000378ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "f436b022",
   "metadata": {},
   "outputs": [],
   "source": [
    "date26=[]\n",
    "author26=[]\n",
    "vertical26=[]\n",
    "headline26=[]\n",
    "description26=[]\n",
    "\n",
    "# scrapping details 26 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date26.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author26.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical26.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline26.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description26.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "3a24139d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df26=pd.DataFrame({})\n",
    "df26['Date']=date26[:1]\n",
    "df26['Author']=author26[:1]\n",
    "df26['Vertical']=vertical26[:1]\n",
    "df26['Healines']=headline26[:1]\n",
    "df26['Description']=description26[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbac75e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "b0555ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "date26a=[]\n",
    "author26a=[]\n",
    "vertical26a=[]\n",
    "headline26a=[]\n",
    "description26a=[]\n",
    "\n",
    "# scrapping details 26 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date26a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author26a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical26a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline26a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description26a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "21178744",
   "metadata": {},
   "outputs": [],
   "source": [
    "df26a=pd.DataFrame({})\n",
    "df26a['Date']=date26a[:1]\n",
    "df26a['Author']=author26a[:1]\n",
    "df26a['Vertical']=vertical26a[:1]\n",
    "df26a['Healines']=headline26a[:1]\n",
    "df26a['Description']=description26a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6735e524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a44796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "0f5063a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "date27=[]\n",
    "author27=[]\n",
    "vertical27=[]\n",
    "headline27=[]\n",
    "description27=[]\n",
    "\n",
    "# scrapping details 27 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date27.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author27.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical27.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline27.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description27.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "4b40756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df27=pd.DataFrame({})\n",
    "df27['Date']=date27[:1]\n",
    "df27['Author']=author27[:1]\n",
    "df27['Vertical']=vertical27[:1]\n",
    "df27['Healines']=headline27[:1]\n",
    "df27['Description']=description27[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5611f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "359d544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "date27a=[]\n",
    "author27a=[]\n",
    "vertical27a=[]\n",
    "headline27a=[]\n",
    "description27a=[]\n",
    "\n",
    "# scrapping details 27 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date27a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author27a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical27a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline27a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description27a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "18e52e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df27a=pd.DataFrame({})\n",
    "df27a['Date']=date27a[:1]\n",
    "df27a['Author']=author27a[:1]\n",
    "df27a['Vertical']=vertical27a[:1]\n",
    "df27a['Healines']=headline27a[:1]\n",
    "df27a['Description']=description27a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd04a677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5ba911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "32426f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "date28=[]\n",
    "author28=[]\n",
    "vertical28=[]\n",
    "headline28=[]\n",
    "description28=[]\n",
    "\n",
    "# scrapping details 28 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date28.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author28.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical28.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline28.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description28.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "8829e948",
   "metadata": {},
   "outputs": [],
   "source": [
    "df28=pd.DataFrame({})\n",
    "df28['Date']=date28[:1]\n",
    "df28['Author']=author28[:1]\n",
    "df28['Vertical']=vertical28[:1]\n",
    "df28['Healines']=headline28[:1]\n",
    "df28['Description']=description28[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def4544b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "fa6347ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "date28a=[]\n",
    "author28a=[]\n",
    "vertical28a=[]\n",
    "headline28a=[]\n",
    "description28a=[]\n",
    "\n",
    "# scrapping details 28 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date28a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author28a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical28a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline28a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description28a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "9f9d85ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df28a=pd.DataFrame({})\n",
    "df28a['Date']=date28a[:1]\n",
    "df28a['Author']=author28a[:1]\n",
    "df28a['Vertical']=vertical28a[:1]\n",
    "df28a['Healines']=headline28a[:1]\n",
    "df28a['Description']=description28a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be7434b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e40e0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "4ebf1a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "date29=[]\n",
    "author29=[]\n",
    "vertical29=[]\n",
    "headline29=[]\n",
    "description29=[]\n",
    "\n",
    "# scrapping details 29 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date29.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author29.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical29.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline29.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description29.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "661da0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df29=pd.DataFrame({})\n",
    "df29['Date']=date29[:1]\n",
    "df29['Author']=author29[:1]\n",
    "df29['Vertical']=vertical29[:1]\n",
    "df29['Healines']=headline29[:1]\n",
    "df29['Description']=description29[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5067849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "bcff1214",
   "metadata": {},
   "outputs": [],
   "source": [
    "date29a=[]\n",
    "author29a=[]\n",
    "vertical29a=[]\n",
    "headline29a=[]\n",
    "description29a=[]\n",
    "\n",
    "# scrapping details 29 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date29a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author29a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical29a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline29a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description29a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "395450aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df29a=pd.DataFrame({})\n",
    "df29a['Date']=date29a[:1]\n",
    "df29a['Author']=author29a[:1]\n",
    "df29a['Vertical']=vertical29a[:1]\n",
    "df29a['Healines']=headline29a[:1]\n",
    "df29a['Description']=description29a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed5a1f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a186d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "30bff8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "date30=[]\n",
    "author30=[]\n",
    "vertical30=[]\n",
    "headline30=[]\n",
    "description30=[]\n",
    "\n",
    "# scrapping details 30 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date30.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author30.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical30.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline30.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description30.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "4c032caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df30=pd.DataFrame({})\n",
    "df30['Date']=date30[:1]\n",
    "df30['Author']=author30[:1]\n",
    "df30['Vertical']=vertical30[:1]\n",
    "df30['Healines']=headline30[:1]\n",
    "df30['Description']=description30[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f06504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "1e19606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "date30a=[]\n",
    "author30a=[]\n",
    "vertical30a=[]\n",
    "headline30a=[]\n",
    "description30a=[]\n",
    "\n",
    "# scrapping details 30 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date30a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author30a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical30a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline30a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description30a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "2b275d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df30a=pd.DataFrame({})\n",
    "df30a['Date']=date30a[:1]\n",
    "df30a['Author']=author30a[:1]\n",
    "df30a['Vertical']=vertical30a[:1]\n",
    "df30a['Healines']=headline30a[:1]\n",
    "df30a['Description']=description30a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe15873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b17391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "7387931b",
   "metadata": {},
   "outputs": [],
   "source": [
    "date31=[]\n",
    "author31=[]\n",
    "vertical31=[]\n",
    "headline31=[]\n",
    "description31=[]\n",
    "\n",
    "# scrapping details 31 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date31.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author31.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical31.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline31.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description31.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "7e385787",
   "metadata": {},
   "outputs": [],
   "source": [
    "df31=pd.DataFrame({})\n",
    "df31['Date']=date31[:1]\n",
    "df31['Author']=author31[:1]\n",
    "df31['Vertical']=vertical31[:1]\n",
    "df31['Healines']=headline31[:1]\n",
    "df31['Description']=description31[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88e659b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "id": "dd90f635",
   "metadata": {},
   "outputs": [],
   "source": [
    "date31a=[]\n",
    "author31a=[]\n",
    "vertical31a=[]\n",
    "headline31a=[]\n",
    "description31a=[]\n",
    "\n",
    "# scrapping details 31 may 2021\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//li[@class='sanspro-semib text-uppercase crud-items__lists']\")\n",
    "for i in dt:\n",
    "    date31a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//a[@class='sanspro-reg article-author__name']\")\n",
    "for i in at:\n",
    "     author31a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//div[@class='item-list']\")\n",
    "for i in ve:\n",
    "    vertical31a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='f-left sanspro-b']\")\n",
    "for i in hd:\n",
    "     headline31a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='field-items']\")\n",
    "for i in desc:\n",
    "    description31a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "763a2253",
   "metadata": {},
   "outputs": [],
   "source": [
    "df31a=pd.DataFrame({})\n",
    "df31a['Date']=date31a[:1]\n",
    "df31a['Author']=author31a[:1]\n",
    "df31a['Vertical']=vertical31a[:1]\n",
    "df31a['Healines']=headline31a[:1]\n",
    "df31a['Description']=description31a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d2789d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d263c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "6cee4eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creatig Dataframes Deccan\n",
    "dfa=pd.concat([df1,df1a,df1b,df1c,df1d,df1e,df1f,df1g,df1h,df1i])\n",
    "\n",
    "dfb=pd.concat([df2,df2a,df2b,df2c,df2d,df2e,df2f,df2g,df2h,df2i])\n",
    "\n",
    "dfc=pd.concat([df3,df3a,df3b,df3c,df3d,df3e,df3f,df3g,df3h,df3i])\n",
    "\n",
    "dfd=pd.concat([df4,df4a,df4b,df4c,df4d,df4e,df4f,df4g,df4h,df4i])\n",
    "\n",
    "dfe=pd.concat([df5,df5a,df5b,df5c,df5d,df5e,df5f,df5g,df5h,df5i])\n",
    "\n",
    "dff=pd.concat([df6,df6a,df6b,df6c,df6d,df6e,df6f,df6g,df6h,df6i])\n",
    "\n",
    "dfg=pd.concat([df7,df7a,df7b,df7c,df7d,df7e,df7f,df7g,df7h,df7i])\n",
    "\n",
    "dfh=pd.concat([df8,df8a,df8b,df8c,df8d,df8e,df8f,df8g,df8h,df8i])\n",
    "\n",
    "dfi=pd.concat([df9,df9a,df9b,df9c,df9d,df9e,df9f,df9g,df9h,df9i])\n",
    "\n",
    "dfj=pd.concat([df10,df10a,df10b,df10c,df10d,df10e,df10f,df10g,df10h,df10i])\n",
    "\n",
    "dfk=pd.concat([df11,df11a,df11b,df11c,df11d,df11e,df11f,df11g,df11h,df11i])\n",
    "\n",
    "dfl=pd.concat([df12,df12a,df12b,df12c,df12d,df12e,df12f,df12g,df12h,df12i])\n",
    "\n",
    "dfm=pd.concat([df13,df13a,df13b,df13c,df13d,df13e,df13f,df13g,df13h,df13i])\n",
    "\n",
    "dfn=pd.concat([df14,df14a,df14b,df14c,df14d,df14e,df14f,df14g,df14h,df14i])\n",
    "\n",
    "dfo=pd.concat([df15,df15a,df15b,df15c,df15d,df15e,df15f,df15g,df15h,df15i])\n",
    "\n",
    "dfp=pd.concat([df16,df16a,df16b,df16c,df16d,df16e,df16f,df16g,df16h,df16i])\n",
    "\n",
    "dfq=pd.concat([df17,df17a,df17b,df17c,df17d,df17e,df17f,df17g,df17h,df17i])\n",
    "\n",
    "dfr=pd.concat([df18,df18a,df18b,df18c,df18d,df18e,df18f,df18g,df18h,df18i])\n",
    "\n",
    "dfs=pd.concat([df19,df19a,df19b,df19c,df19d,df19e,df19f,df19g,df19h,df19i])\n",
    "\n",
    "dft=pd.concat([df20,df20a,df20b,df20c,df20d,df20e,df20f,df20g,df20h,df20i])\n",
    "\n",
    "dfu=pd.concat([df21,df21a,df21b,df21c,df21d,df21e,df21f,df21g,df21h,df21i])\n",
    "\n",
    "dfv=pd.concat([df22,df22a,df22b,df22c,df22d,df22e,df22f,df22g,df22h,df22i])\n",
    "\n",
    "dfw=pd.concat([df23,df23a,df23b,df23c,df23d,df23e,df23f,df23g,df23h,df23i])\n",
    "\n",
    "dfx=pd.concat([df24,df24a,df24b,df24c,df24d,df24e,df24f,df24g,df24h,df24i])\n",
    "\n",
    "dfy=pd.concat([df25,df25a])\n",
    "\n",
    "dfz=pd.concat([df26,df26a])\n",
    "\n",
    "dfz1=pd.concat([df27,df27a])\n",
    "\n",
    "dfz2=pd.concat([df28,df28a])\n",
    "\n",
    "dfz3=pd.concat([df29,df29a])\n",
    "\n",
    "dfz4=pd.concat([df30,df31a])\n",
    "\n",
    "dfz5=pd.concat([df31,df31a])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "905c28f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([dfa,dfb,dfc,dfd,dfe,dff,dfg,dfh,dfi,dfj,dfk,dfl,dfm,dfn,dfo,dfp,dfq,dfr,dfs,dft,dfu,dfv,dfw,dfx,dfy,dfz,dfz1,dfz2,dfz3,dfz4,dfz5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "ec3a5337",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reset=df.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "ab1b09b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Vertical</th>\n",
       "      <th>Healines</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAY 01 2021, 00:44 IST</th>\n",
       "      <td>DH Web Desk,</td>\n",
       "      <td>Assam Polls 2021: Constituency-wise Results Live</td>\n",
       "      <td>Assam Election Result 2021: Constituency-wise ...</td>\n",
       "      <td>Officials wait to undergo Covid-19 testing on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAY 01 2021, 03:48 IST</th>\n",
       "      <td>Rajiv Vijayakar,</td>\n",
       "      <td>Home\\nEntertainment\\nArts, Books &amp; Culture\\nRa...</td>\n",
       "      <td>Rahman: The way music is consumed has changed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAY 01 2021, 04:00 IST</th>\n",
       "      <td>Chetan Vinchhi,</td>\n",
       "      <td>Home\\nEntertainment\\nArts, Books &amp; Culture\\nRa...</td>\n",
       "      <td>Rajan Mishra was golden voice of Banaras tradi...</td>\n",
       "      <td>Pandit Rajan Mishra (right) with his younger b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAY 01 2021, 04:13 IST</th>\n",
       "      <td>Vivek M V,</td>\n",
       "      <td>Home\\nEntertainment\\nArts, Books &amp; Culture\\nKa...</td>\n",
       "      <td>Karnataka artistes remember maestro Rajan Mishra</td>\n",
       "      <td>Ravindra Katoti and (right) Vyasmurti Katti.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAY 01 2021, 00:44 IST</th>\n",
       "      <td>DH Web Desk,</td>\n",
       "      <td>Home\\nElection\\nAssam\\nAssam Polls 2021: Const...</td>\n",
       "      <td>Assam Election Result 2021: Constituency-wise ...</td>\n",
       "      <td>Officials wait to undergo Covid-19 testing on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAY 29 2021, 00:42 IST</th>\n",
       "      <td>HM Chaithanya Swamy,</td>\n",
       "      <td>Home\\nCity\\nBengaluru Crime\\nGambling at de-ad...</td>\n",
       "      <td>Gambling at de-addiction centre</td>\n",
       "      <td>A drug de-addiction centre that doubled up as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAY 30 2021, 00:50 IST</th>\n",
       "      <td>HM Chaithanya Swamy,</td>\n",
       "      <td>Home\\nCity\\nBengaluru Crime\\nBar sells alcohol...</td>\n",
       "      <td>Bar sells alcohol beyond 10 am for double the MRP</td>\n",
       "      <td>Credit: DH Photo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAY 31 2021, 00:37 IST</th>\n",
       "      <td>Annapurna Singh,</td>\n",
       "      <td>Home\\nBusiness\\nCentre offers loan guarantee f...</td>\n",
       "      <td>Centre offers loan guarantee for hospital oxyg...</td>\n",
       "      <td>The move comes against the backdrop of an unpr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAY 31 2021, 00:59 IST</th>\n",
       "      <td>DHNS,</td>\n",
       "      <td>Home\\nCity\\nBengaluru Infrastructure\\nGovt wor...</td>\n",
       "      <td>Karnataka govt working on sprawling tree park ...</td>\n",
       "      <td>Credit: DH Photo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAY 31 2021, 00:37 IST</th>\n",
       "      <td>Annapurna Singh,</td>\n",
       "      <td>Home\\nBusiness\\nCentre offers loan guarantee f...</td>\n",
       "      <td>Centre offers loan guarantee for hospital oxyg...</td>\n",
       "      <td>The move comes against the backdrop of an unpr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Author  \\\n",
       "Date                                           \n",
       "MAY 01 2021, 00:44 IST          DH Web Desk,   \n",
       "MAY 01 2021, 03:48 IST      Rajiv Vijayakar,   \n",
       "MAY 01 2021, 04:00 IST       Chetan Vinchhi,   \n",
       "MAY 01 2021, 04:13 IST            Vivek M V,   \n",
       "MAY 01 2021, 00:44 IST          DH Web Desk,   \n",
       "...                                      ...   \n",
       "MAY 29 2021, 00:42 IST  HM Chaithanya Swamy,   \n",
       "MAY 30 2021, 00:50 IST  HM Chaithanya Swamy,   \n",
       "MAY 31 2021, 00:37 IST      Annapurna Singh,   \n",
       "MAY 31 2021, 00:59 IST                 DHNS,   \n",
       "MAY 31 2021, 00:37 IST      Annapurna Singh,   \n",
       "\n",
       "                                                                 Vertical  \\\n",
       "Date                                                                        \n",
       "MAY 01 2021, 00:44 IST   Assam Polls 2021: Constituency-wise Results Live   \n",
       "MAY 01 2021, 03:48 IST  Home\\nEntertainment\\nArts, Books & Culture\\nRa...   \n",
       "MAY 01 2021, 04:00 IST  Home\\nEntertainment\\nArts, Books & Culture\\nRa...   \n",
       "MAY 01 2021, 04:13 IST  Home\\nEntertainment\\nArts, Books & Culture\\nKa...   \n",
       "MAY 01 2021, 00:44 IST  Home\\nElection\\nAssam\\nAssam Polls 2021: Const...   \n",
       "...                                                                   ...   \n",
       "MAY 29 2021, 00:42 IST  Home\\nCity\\nBengaluru Crime\\nGambling at de-ad...   \n",
       "MAY 30 2021, 00:50 IST  Home\\nCity\\nBengaluru Crime\\nBar sells alcohol...   \n",
       "MAY 31 2021, 00:37 IST  Home\\nBusiness\\nCentre offers loan guarantee f...   \n",
       "MAY 31 2021, 00:59 IST  Home\\nCity\\nBengaluru Infrastructure\\nGovt wor...   \n",
       "MAY 31 2021, 00:37 IST  Home\\nBusiness\\nCentre offers loan guarantee f...   \n",
       "\n",
       "                                                                 Healines  \\\n",
       "Date                                                                        \n",
       "MAY 01 2021, 00:44 IST  Assam Election Result 2021: Constituency-wise ...   \n",
       "MAY 01 2021, 03:48 IST      Rahman: The way music is consumed has changed   \n",
       "MAY 01 2021, 04:00 IST  Rajan Mishra was golden voice of Banaras tradi...   \n",
       "MAY 01 2021, 04:13 IST   Karnataka artistes remember maestro Rajan Mishra   \n",
       "MAY 01 2021, 00:44 IST  Assam Election Result 2021: Constituency-wise ...   \n",
       "...                                                                   ...   \n",
       "MAY 29 2021, 00:42 IST                    Gambling at de-addiction centre   \n",
       "MAY 30 2021, 00:50 IST  Bar sells alcohol beyond 10 am for double the MRP   \n",
       "MAY 31 2021, 00:37 IST  Centre offers loan guarantee for hospital oxyg...   \n",
       "MAY 31 2021, 00:59 IST  Karnataka govt working on sprawling tree park ...   \n",
       "MAY 31 2021, 00:37 IST  Centre offers loan guarantee for hospital oxyg...   \n",
       "\n",
       "                                                              Description  \n",
       "Date                                                                       \n",
       "MAY 01 2021, 00:44 IST  Officials wait to undergo Covid-19 testing on ...  \n",
       "MAY 01 2021, 03:48 IST                                                     \n",
       "MAY 01 2021, 04:00 IST  Pandit Rajan Mishra (right) with his younger b...  \n",
       "MAY 01 2021, 04:13 IST       Ravindra Katoti and (right) Vyasmurti Katti.  \n",
       "MAY 01 2021, 00:44 IST  Officials wait to undergo Covid-19 testing on ...  \n",
       "...                                                                   ...  \n",
       "MAY 29 2021, 00:42 IST  A drug de-addiction centre that doubled up as ...  \n",
       "MAY 30 2021, 00:50 IST                                   Credit: DH Photo  \n",
       "MAY 31 2021, 00:37 IST  The move comes against the backdrop of an unpr...  \n",
       "MAY 31 2021, 00:59 IST                                   Credit: DH Photo  \n",
       "MAY 31 2021, 00:37 IST  The move comes against the backdrop of an unpr...  \n",
       "\n",
       "[254 rows x 4 columns]"
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "80092a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving into csv\n",
    "df_reset.to_csv('deccan_herald_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4394c584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fca0ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
