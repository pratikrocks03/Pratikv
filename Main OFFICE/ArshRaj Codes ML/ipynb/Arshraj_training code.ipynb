{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "try:\n",
    "    import os\n",
    "    import sys\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    print(f'Default working directory {os.getcwd()}')\n",
    "    #change the directory to working directory\n",
    "    #path =r\"C:\\Work_Anaconda\\TripAdvisor\\All_script_voting\"\n",
    "   # path =r\"C:\\Users\\arshraj.randhawa\\Desktop\\work2022\\reikit model building\"\n",
    "    os.chdir(path)\n",
    "    print(f'Current working directory {os.getcwd()}')\n",
    "    #check the files in directory\n",
    "    # print(f'Files in the current working directory are:\\n{os.listdir()}')\n",
    "except Exception as e:\n",
    "    print(f'Error while setting up working directory : {sys.exc_info()[0]} , {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Libraries & functions\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msupport_file2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'support_file2'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLibrabries and functions imported successfull\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError while importing librabries \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m , \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sys' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Importing Libraries & functions')\n",
    "try :\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    import spacy\n",
    "    #if spacy is not installed >>\n",
    "    # pip install -U spacy\n",
    "    # python -m spacy download en_core_web_lg\n",
    "    import pandas as pd\n",
    "    import joblib\n",
    "    # pip install joblib\n",
    "    import numpy as np\n",
    "#     import glob\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from support_file2 import *\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from nltk.tokenize import sent_tokenize\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn import metrics\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.feature_selection import SelectFromModel\n",
    "    from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    from sklearn.naive_bayes import ComplementNB\n",
    "    from sklearn.metrics import precision_score\n",
    "    from sklearn.metrics import recall_score\n",
    "    from sklearn.metrics import f1_score\n",
    "    print('Librabries and functions imported successfull')\n",
    "except Exception as e:\n",
    "    print(f'Error while importing librabries {sys.exc_info()[0]} , {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing new training data from Database\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#         df = pd.read_pickle('ta_snippet_10032021.pkl')\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m#only the 4 columns are necessary\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mReviewID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMonth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTitle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mReview\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFullText\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRating\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTitle_Review\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLevel1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLevel2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLevel3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     10\u001b[0m     head, shape, dtyp, colms, nul \u001b[38;5;241m=\u001b[39m dfinfo(df)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3510\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3511\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3513\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5782\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5784\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5842\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5841\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 5842\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5844\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['ReviewID', 'Month', 'Title', 'Review', 'FullText', 'Rating',\\n       'Title_Review', 'Level1', 'Level2', 'Level3'],\\n      dtype='object')] are in the [columns]\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m col\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while fetching the data data : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sys' is not defined"
     ]
    }
   ],
   "source": [
    "print('Importing new training data from Database')\n",
    "try:\n",
    "    #read data from the source\n",
    "    # df = pd.read_sql_query()\n",
    "\n",
    "    df = pd.read_excel('Lysol SS 8th - 14th Sept.xlsx')\n",
    "#         df = pd.read_pickle('ta_snippet_10032021.pkl')\n",
    "    #only the 4 columns are necessary\n",
    "    df = df[['ReviewID','Month', 'Title', 'Review', 'FullText','Rating','Title_Review','Level1','Level2','Level3']]\n",
    "    head, shape, dtyp, colms, nul = dfinfo(df)\n",
    "    #sort\n",
    "    df.columns = [col.lower() for col in colms]\n",
    "    df.sort_values(['reviewid', 'title'], inplace=True)\n",
    "    df.dropna(subset=['review'],inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    #lowering all text columns\n",
    "    for col in ['title','month','review', 'fulltext', 'title_review']:\n",
    "        df[col] = df[col].str.lower()\n",
    "        df[col] = df[col].str.strip()\n",
    "    del col\n",
    "except Exception as e:\n",
    "    print(f\"Error while fetching the data data : {sys.exc_info()[0]} : {e}\")\n",
    "# df = df[['userreviewid', 'reviewtext']].drop_duplicates('userreviewid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.groupby(\"level1\").size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "level1\n",
       "Adverse Event               76\n",
       "Brand Perception          1252\n",
       "Functionality             4980\n",
       "Manufacturing & Design     704\n",
       "Platform Experience        949\n",
       "Pricing                    759\n",
       "Product Features          1485\n",
       "Usability                  239\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"level1\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10444 entries, 0 to 10443\n",
      "Data columns (total 10 columns):\n",
      "reviewid        10444 non-null object\n",
      "month           10444 non-null object\n",
      "title           10389 non-null object\n",
      "review          10444 non-null object\n",
      "fulltext        2392 non-null object\n",
      "rating          10444 non-null int64\n",
      "title_review    10444 non-null object\n",
      "level1          10444 non-null object\n",
      "level2          10444 non-null object\n",
      "level3          10444 non-null object\n",
      "dtypes: int64(1), object(9)\n",
      "memory usage: 816.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preproceing starts...\n",
      "removed emojis\n",
      "removed punctuation\n",
      "removed blank lines\n",
      "lematization of text is in process...\n",
      "lemmmatized text\n",
      "removed stop words\n",
      "removed single words\n",
      "removed digits\n",
      "removed white spaces\n",
      "reviewid>month>title>review>fulltext>rating>title_review>level1>level2>level3>cc1>Error in preprocessing: <class 'TypeError'> , object of type 'float' has no len()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =========================Pre processing======================================\n",
    "\n",
    "print('Preproceing starts...')\n",
    "try:\n",
    "    df['review'] = df['review'].apply(cleantext)\n",
    "    df = preprocess(df, 'review')\n",
    "    df['cc1'] = df['cc1'].replace('', np.nan)\n",
    "    head, shape, dtyp, colms, nul = dfinfo(df)\n",
    "    nullreco = df[df['cc1'].isna()]\n",
    "    #drop nul values\n",
    "    dupli = df[df.duplicated(subset = ['reviewid', 'cc1'], keep=False)]\n",
    "    df = df.drop_duplicates(subset=['reviewid', 'cc1']).reset_index(drop=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    #preparing dictionary d\n",
    "    head, shape, dtyp, colms, nul = dfinfo(df)\n",
    "    colms.remove('cc')\n",
    "    d = uniq(df[colms])\n",
    "    colms = list(df.columns)\n",
    "    df['word'] = df['cc1'].str.split().str.len()\n",
    "    df['len'] = df['cc1'].apply(len)\n",
    "#     df = df[['reviewid', 'snippet', 'theme', 'sentiment', 'cc', 'cc1', '#word', 'len']]\n",
    "    print('\\nPreproceing of new Done')\n",
    "except Exception as e:\n",
    "    print(f'Error in preprocessing: {sys.exc_info()[0]} , {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10444 entries, 0 to 10443\n",
      "Data columns (total 13 columns):\n",
      "reviewid        10444 non-null object\n",
      "month           10444 non-null object\n",
      "title           10389 non-null object\n",
      "review          10444 non-null object\n",
      "fulltext        2392 non-null object\n",
      "rating          10444 non-null int64\n",
      "title_review    10444 non-null object\n",
      "level1          10444 non-null object\n",
      "level2          10444 non-null object\n",
      "level3          10444 non-null object\n",
      "cc              10444 non-null object\n",
      "cc1             10389 non-null object\n",
      "word            10389 non-null float64\n",
      "dtypes: float64(1), int64(1), object(11)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month\n",
       "april     2234\n",
       "august    2389\n",
       "july      2142\n",
       "june      1942\n",
       "may       1737\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('month').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing data to train the model\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "print('preparing data to train the model')\n",
    "try:\n",
    "    le = LabelEncoder()\n",
    "    df['theme_enco'] = le.fit_transform(df['level1'])\n",
    "    joblib.dump(le, 'le')\n",
    "    #prepare X\n",
    "    df['cc1']=df['cc1'].values.astype('U')\n",
    "    test=df[df.month==\"august\"]\n",
    "    train=df[df.month!=\"august\"]\n",
    "    x=df[\"cc1\"]\n",
    "    y=df[\"theme_enco\"]\n",
    "    X_train=train[\"cc1\"]\n",
    "    X_test=test[\"cc1\"]\n",
    "    y_train=train['theme_enco']\n",
    "    y_test=test['theme_enco']\n",
    "#     x = df['cc1']\n",
    "    #prepare Y\n",
    "#     y =df['theme_enco']\n",
    "    # y =df1['theme']\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=1, random_state=42)\n",
    "    \n",
    "#     y_trainindex = y_train.index\n",
    "#     y_testindex = y_test.index\n",
    "except Exception as e:\n",
    "    print(f'Error preparing data to train the model :{sys.exc_info()[0]} , {e}')\n",
    "\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8055,)\n",
      "(2389,)\n",
      "(8055,)\n",
      "(2389,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started feature engineering\n",
      "Feature selection going on, it may take a while\n",
      "Feature engineering is done successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print('Started feature engineering')\n",
    "    tf = TfidfVectorizer(ngram_range=(1, 2))\n",
    "    tf.fit(x)\n",
    "    joblib.dump(tf, 'tf', compress=5)\n",
    "    x_train = tf.transform(X_train)\n",
    "    x_test = tf.transform(X_test)\n",
    "    print('Feature selection going on, it may take a while')\n",
    "    selector = SelectFromModel(ExtraTreesClassifier(n_estimators=100,random_state=2021)).fit(x_train, y_train)\n",
    "    joblib.dump(selector, 'selector', compress=5)\n",
    "    # selector = joblib.load('selector')\n",
    "    x_train = selector.transform(x_train)\n",
    "    x_test = selector.transform(x_test)\n",
    "    print('Feature engineering is done successfully')\n",
    "except Exception as e:\n",
    "    print(f'Error feature engineering : {sys.exc_info()[0]} , {e}')\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8055, 8502)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SGD model\n",
      "Training GBoosting model\n",
      "Training ComplementNB model\n",
      "All ML Model trained dumped successfully\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "try:\n",
    "    print(\"Training SGD model\")\n",
    "    m_sgd = SGDClassifier(loss='modified_huber', class_weight='balanced', random_state=2022)\n",
    "    m_sgd.fit(x_train, y_train)\n",
    "    joblib.dump(m_sgd, 'm_sgd', compress=5)\n",
    "    \n",
    "    print(\"Training GBoosting model\")\n",
    "    m_gbt = GradientBoostingClassifier(loss='deviance', random_state=2022)\n",
    "    #exponential loss require 2 class\n",
    "    m_gbt.fit(x_train, y_train)\n",
    "    joblib.dump(m_gbt, 'm_gbt', compress=5)\n",
    "\n",
    "    print(\"Training ComplementNB model\")    \n",
    "    m_cnb = ComplementNB()\n",
    "    m_cnb.fit(x_train, y_train)\n",
    "    joblib.dump(m_cnb, 'm_cnb', compress=5)\n",
    "\n",
    "    # print(\"Voting algorithm running\")\n",
    "    # from sklearn.ensemble import VotingClassifier\n",
    "    # vclassifier = VotingClassifier(estimators=[('sgd', m_sgd), ('gbt', m_gbt), ('cnb', m_cnb)], voting='soft')\n",
    "    # vclassifier =  vclassifier.fit(x_train, y_train)\n",
    "    # joblib.dump(vclassifier, 'vclassifier', compress=5)\n",
    "    print('All ML Model trained dumped successfully')\n",
    "except Exception as e:\n",
    "    print(f'Error in model training model : {sys.exc_info()[0]} , {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the prediction on data\n"
     ]
    }
   ],
   "source": [
    "print('Running the prediction on data')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_sgd model 0.6848053578903307\n",
      "[[  6   0   8   0   0   0   1   0]\n",
      " [  0 178  67  12   6   6  13   2]\n",
      " [  2  53 881  26  20  23  78  11]\n",
      " [  0  15  42 113  12   1   8   6]\n",
      " [  1  17  38  10 165   9   7   3]\n",
      " [  0   8  43   2   4  99   9   1]\n",
      " [  3   4 117  13  12   9 178   3]\n",
      " [  1   0  17   4   0   3   3  16]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'f1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-01c1ecfb3b64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"m_sgd model\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"theme\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtheme\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"theme\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtheme\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'F1: %f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mf1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'f1' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "pred_sgd = m_sgd.predict_proba(x_test)\n",
    "# pred_sgd = m_gbt.predict_proba(x_test)\n",
    "# pred_sgd = m_cnb.predict_proba(x_test)\n",
    "pred = pd.DataFrame(data=pred_sgd, columns=le.classes_)\n",
    "pred['max'] = np.max(pred, axis=1)\n",
    "pred['max'] = np.max(pred, axis=1)\n",
    "pred['theme'] = pred.idxmax(axis=1)\n",
    "test['m_sgd'] = pred['max'].tolist()\n",
    "test['m_sgd_prob'] = pred['theme'].tolist()\n",
    "theme=pd.DataFrame(le.inverse_transform(y_test),columns=[\"actual_theme\"])\n",
    "print(\"m_sgd model\",accuracy_score(pred[\"theme\"],theme))\n",
    "print(confusion_matrix(pred[\"theme\"],theme))\n",
    "print('F1: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# pred_sgd = m_sgd.predict_proba(x_test)\n",
    "pred_sgd = m_gbt.predict_proba(x_test)\n",
    "# pred_sgd = m_cnb.predict_proba(x_test)\n",
    "pred = pd.DataFrame(data=pred_sgd, columns=le.classes_)\n",
    "pred['max'] = np.max(pred, axis=1)\n",
    "pred['max'] = np.max(pred, axis=1)\n",
    "pred['theme'] = pred.idxmax(axis=1)\n",
    "test['m_gbt'] = pred['max'].tolist()\n",
    "test['m_gbt_prob'] = pred['theme'].tolist()\n",
    "theme=pd.DataFrame(le.inverse_transform(y_test),columns=[\"actual_theme\"])\n",
    "print(\"m_gbt model\",accuracy_score(pred[\"theme\"],theme))\n",
    "print(confusion_matrix(pred[\"theme\"],theme))\n",
    "precision = precision_score(pred[\"theme\"],theme,pos_label='positive', average='micro')\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(pred[\"theme\"],theme,pos_label='positive', average='micro')\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(pred[\"theme\"],theme,pos_label='positive', average='micro')\n",
    "print('F1: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sgd = m_cnb.predict_proba(x_test)\n",
    "pred = pd.DataFrame(data=pred_sgd, columns=le.classes_)\n",
    "pred['max'] = np.max(pred, axis=1)\n",
    "pred['max'] = np.max(pred, axis=1)\n",
    "pred['theme'] = pred.idxmax(axis=1)\n",
    "test['m_cnb'] = pred['max'].tolist()\n",
    "test['m_cnb_prob'] = pred['theme'].tolist()\n",
    "theme=pd.DataFrame(le.inverse_transform(y_test),columns=[\"actual_theme\"])\n",
    "print(\"m_cnb model\",accuracy_score(pred[\"theme\"],theme))\n",
    "print(confusion_matrix(pred[\"theme\"],theme))\n",
    "precision = precision_score(pred[\"theme\"],theme,pos_label='positive', average='micro')\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(pred[\"theme\"],theme,pos_label='positive', average='micro')\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(pred[\"theme\"],theme,pos_label='positive', average='micro')\n",
    "print('F1: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.to_csv(\"sampleoutout.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
